# -*- coding: utf-8 -*-
"""Copy of HCMUT-SCHEDULING-Sol-2 (refactored + docs).ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1Jfz8pd3yo2aMwkaYyR7IoBUekhKnIUsu

<!DOCTYPE html>
<html>
<head>
    <style>
        table {
            width: 50%;
            border-collapse: collapse;
            margin: 20px auto;
        }
        th, td {
            border: 1px solid #dddddd;
            text-align: left;
            padding: 15px;
        }
        th {
            background-color: #f2f2f2;
        }
    </style>
</head>
<body>
<center>
<img src="https://hcmut.edu.vn/img/nhanDienThuongHieu/bk_name_en.png" alt="hcmut logo"/>

<table>
    <tr>
        <th>Role</th>
        <th>Name</th>
        <th>ID</th>
    </tr>
    <tr>
        <td>Institution</td>
        <td>Ho Chi Minh University of Technology</td>
        <td></td>
    </tr>
    <tr>
        <td>Instructor</td>
        <td>Quan Thanh Tho</td>
    </tr>
    <tr>
        <td></td>
        <td>Nguyen Minh Tam</td>
    </tr>
    <tr>
        <td>Members</td>
        <td>Cao Tri</td>
        <td>2010733</td>
    </tr>
    <tr>
        <td></td>
        <td>Vu Vinh</td>
        <td></td>
    </tr>
    <tr>
        <td></td>
        <td>Pham Quang</td>
        <td></td>
    </tr>
</table>

</center>
</body>
</html>

# Introduction
Mục tiêu là sắp xếp các lớp học vào thời khóa biểu. Vì sao lại là lớp học, vì lớp học là 1 chủ thể unique, từ đây có thể định ra được teacher và các student tham gia

Xem thêm tại `brainstorm.docs` trong cùng thư mục
"""

# from google.colab import drive
# drive.mount('/gdrive', force_remount=True)
#
# !ls /gdrive/MyDrive/HCMUT-Scheduling/
#
# !cp /gdrive/MyDrive/HCMUT-Scheduling/Dự-kiến-SVMT_241.xlsx /content/
# !cp /gdrive/MyDrive/HCMUT-Scheduling/"Dự kiến SVMT_241 (thầy Cường).xlsx" /content/
# !cp /gdrive/MyDrive/HCMUT-Scheduling/"final_TKB_update20230915.xlsx" /content/

import os

from holoviews.ipython import display
from matplotlib import pyplot as plt
from tqdm import tqdm
import numpy as np
import pandas as pd
import random
from copy import deepcopy
from collections import namedtuple
from typing import Union, List
import calendar
import math
import pandas as pd
from collections import defaultdict
from itertools import combinations

# import gdown

# url_dk241 = "https://docs.google.com/spreadsheets/d/1hV1XwhXpQaPgd0mTZ8_xmxIyRPpVEXyQ/edit?usp=drive_link&ouid=105374451612561775917&rtpof=true&sd=true"
# sheet_dk241 = "Dự-kiến-SVMT_241.xlsx"
# url_dk241_thaycuong = "https://docs.google.com/spreadsheets/d/1WQFBxemnXNcpHL9bGma3TTBcw50y9x24/edit?usp=drive_link&ouid=105374451612561775917&rtpof=true&sd=true"
# sheet_dk241_thaycuong = "Dự kiến SVMT_241 (thầy Cường).xlsx"
# url_tkb231 = "https://docs.google.com/spreadsheets/d/1QyUzXdfXU0os2TeVQ5qtCrUj6SqvRtiJ/edit?usp=drive_link&ouid=105374451612561775917&rtpof=true&sd=true"
# sheet_tkb231 = "final_TKB_update20230915.xlsx"
# gdown.download(url_dk241, sheet_dk241, quiet=False)
# gdown.download(url_dk241_thaycuong, sheet_dk241_thaycuong, quiet=False)
# gdown.download(url_tkb231, sheet_tkb231, quiet=False)

random.seed(42)  # cố định kết quả chạy vì có sử dụng random

SHEET_FILE_NAME = "Dự-kiến-SVMT_241.xlsx"
FIXED_SHEET_FILE_NAME = ["Dự kiến SVMT_241 (thầy Cường).xlsx"]  # sau này nếu có thêm file đề xuất thì append vào
REFERENCE_SHEET_FILE_NAME = "final_TKB_update20230915.xlsx"  # file tham khảo từ 1 học kỳ trước. Ở đây là 231
LAB_SHEET_FILE_NAME = "HK241_CSE_Xep TKB ThucHanh-ThiNghiem.xlsx"
LAB_SHEET_NAMES = ['HK241 TKB LAB', 'CS1', 'CS2']
SHEET_FILE_PATH = f"/Users/twang/Documents/GitHub/Sched/{SHEET_FILE_NAME}"
SHEET_NAMES = ['Thống kê', 'Phản hồi', 'KHGD', 'Môn học', 'reference']  # 'reference' đại diện cho file HK231

assert os.path.exists(SHEET_FILE_PATH)
assert all(os.path.exists(fixed_sheet_file) for fixed_sheet_file in FIXED_SHEET_FILE_NAME)
assert os.path.exists(REFERENCE_SHEET_FILE_NAME)

data0 = pd.read_excel(SHEET_FILE_PATH, sheet_name=SHEET_NAMES[0])
data0

data1 = pd.read_excel(SHEET_FILE_PATH, sheet_name=SHEET_NAMES[1])
data1

data2 = pd.read_excel(SHEET_FILE_PATH, sheet_name=SHEET_NAMES[2])
data2

data3 = pd.read_excel(SHEET_FILE_PATH, sheet_name=SHEET_NAMES[3])
data3

data4 = pd.read_excel(FIXED_SHEET_FILE_NAME[0], sheet_name=SHEET_NAMES[1])
data4

data0 = data0.dropna(subset=['Số lượng nhóm'])
data0.info()

data0.groupby(['Sỉ số SV max', 'Loại hình lớp'])['Số lượng nhóm'].sum()

"""**Từ quan sát, nhận thấy, file tham khảo (HK231) khi được fixed vào sau cùng sau khi đã thông qua đề xuất của các thầy, thì file tham khảo nào cũng như 1 file đề xuất của 1 thầy ẩn danh. Do đó, mục tiêu là chuyển đổi format hiện tại của file tham khảo về như 1 file đề xuất (của các thầy).**"""

ref_data = pd.read_excel(REFERENCE_SHEET_FILE_NAME)
# Lọc của khoa máy tính & không phải thí nghiệm
# ref_data = ref_data[(ref_data['f_makhoa'] == 'MT')]
# ref_data


# Một số môn ở học kỳ này bị split thời khoa biểu, do đó cần merge lại
def overlap_splited_rows(ref_data):
    # Group by the columns that define duplicates
    grouped = ref_data.groupby(['f_mamh', 'f_manh'])

    # Define an aggregation function that returns the first non-null value
    def first_non_null(series):
        return series.dropna().iloc[0] if not series.dropna().empty else None

    # Apply the aggregation function to each group
    return grouped.agg(first_non_null).reset_index()


ref_data = overlap_splited_rows(ref_data)

"""## Mapped Variables"""

# ROOM_ID = ["CQ", "CC", "CN"]

FACULTY_ID = {
    "Khoa học máy tính": "CS",
    "Kỹ thuật máy tính": "CE"
}

PROGRAM_ID = {
    "Chương trình giảng  dạy bằng tiếng Anh": "CC",
    "Chương trình giảng dạy bằng tiếng Anh": "CC",
    "Chương trình tiêu chuẩn": "CQ",
    "Chương trình định hướng Nhật Bản": "CN",
    "Cử nhân tài năng": "TN"
}
PROGRAM_ID_REVERSE = {value: key for key, value in PROGRAM_ID.items()}

ROOM_TYPE_ID = {
    30.0: "1",
    39.0: "2",
    40.0: "3",
    60.0: "4",
    80.0: "5",
    140.0: "6",
    160.0: "7",
    200.0: "8",
}

LAB_ROOM_TYPE_ID = {
    30.0: "1",  #104-C6
    30.1: "2",  #508-C6
    30.2: "3",  #510-C6

    39.0: "4",  #202-C5
    39.1: "5",  #105-C6
    39.2: "6",  #102-C6
    39.3: "7",  #103-C6
    39.4: "8",  #509-C6
    39.5: "9",  #303-B9

    40.1: "10",  #601-H6
    40.2: "11",  #603-H6
    40.3: "12",  #604-H6
    40.4: "13",  #605-H6
    40.5: "14",  #701-H6
    40.6: "15",  #702-H6
    40.7: "16",  #703-H6
    40.8: "17",  #707-H6
    40.9: "18",  #708-H6
}

ROOM_TYPE_ID_REVERSE = {val: key for key, val in ROOM_TYPE_ID.items()}
LAB_ROOM_TYPE_ID_REVERSE = {val: key for key, val in LAB_ROOM_TYPE_ID.items()}

# Lưu ý: đây là trường hợp cho kết quả tốt nhất (có lẽ vì phân phối của phòng tương đương với ```data0['Sỉ số SV max'].value_counts()``` bên trên)
# Với số phòng nhỏ hơn, GA ko hội tụ. Do đó cần cung cấp số liệu chính xác hoặc GA cải tiến đa mục tiêu
# Kết quả đo đạc dưới phần Appendix
NUMBER_OF_ROOM = {  # '-'.join(facility, room_type_id) BK-DAn, BK-LTK
    "DAn-1": 4,  # loại phòng 30 chỗ
    "DAn-2": 5,  # loại phòng 400 chỗ (hội trường, 211H1)
    "DAn-3": 28,  # loại phòng 40 chỗ
    "DAn-4": 15,  # loại phòng 60 chỗ
    "DAn-5": 15,  # loại phòng 80 chỗ
    "DAn-6": 15,  # loại phòng 140 chỗ
    "DAn-7": 15,  # loại phòng 160 chỗ
    "DAn-8": 10,  # loại phòng 200 chỗ (hội trường, 211H1)

    "LTK-1": 1,
    "LTK-2": 4,
    "LTK-3": 25,
    "LTK-4": 15,
    "LTK-5": 15,
    "LTK-6": 15,
    "LTK-7": 15,
    "LTK-8": 10,
}

NUMBER_OF_ROOM_LAB = {
    "DA-1": 0,
    "DA-2": 0,
    "DA-3": 0,
    "DA-4": 0,
    "DA-5": 0,
    "DA-6": 0,
    "DA-7": 0,
    "DA-8": 0,
    "DA-9": 0,
    "DA-10": 1,
    "DA-11": 1,
    "DA-12": 1,
    "DA-13": 1,
    "DA-14": 1,
    "DA-15": 1,
    "DA-16": 1,
    "DA-17": 1,
    "DA-18": 1,

    "LTK-1": 1,
    "LTK-2": 1,
    "LTK-3": 1,
    "LTK-4": 1,
    "LTK-5": 1,
    "LTK-6": 1,
    "LTK-7": 1,
    "LTK-8": 1,
    "LTK-9": 1,
    "LTK-10": 0,
    "LTK-11": 0,
    "LTK-12": 0,
    "LTK-13": 0,
    "LTK-14": 0,
    "LTK-15": 0,
    "LTK-16": 0,
    "LTK-17": 0,
    "LTK-18": 0,
}

FACILITY_ID = {
    "LTK": 1,
    "DAn": 2
}

FACILITY = {
    "L": "DAn",
    "CC": "LTK",
    "CN": "LTK",
    "TN": "DAn"
}

MAX_ACTIVE_WEEKS = 18  # max number of weeks which is active

PROGRAM_ID_TO_GROUP_ID = {
    "CQ": "L",
    "CC": "CC",
    "CN": "CN",
    "TN": "TN"
}

GROUP_ID_TO_PROGRAM_ID = {val: key for key, val in PROGRAM_ID_TO_GROUP_ID.items()}

VALID_DAY = range(2, 7)  # active day of university, except Saturday and Sunday
VALID_SESSION_START = range(2, 12)  # active session start, 11 mean 16h, I think the shortest class must be in 2 hours
VALID_ROOM_TYPE_ID = [str(r) for r in range(1, 9)]
VALID_SESSION = range(2, 14)

VI_TO_EN_COLUMN_NAMES = {
    'Mã môn học': 'subject_id',
    'Loại hình lớp': 'program',
    'Số lượng nhóm': 'num_of_group',
    'Sỉ số SV max': 'room_cap_id',
    'Mã nhóm': 'group_id',
    'Số tiết': 'num_session',
    'Số tuần học': 'num_of_learning_week',
    'Tuần kiểm tra giữa kỳ': 'midterm_week',
    'Học kỳ chính': 'main_term',
    'Tên ngành': 'faculty',
    'Thứ': 'day',
    "Thứ ": 'day',
    'Tiết BD': 'session_start',
    ######
    'f_mamh': 'subject_id',
    'f_manh': 'group_id',
    'f_sotiet': 'num_session',
    'f_manv': 'teacher_id',
    'f_thu': 'day',
    'f_tietbd': 'session_start',
    'f_tenph': 'room_name',
}

MIDTERM_ALL = 8

"""## Preprocess Sheet File"""


# Đây là hàm thống nhất để preprocess tất cả sheet file
def preprocess_raw_data(df, sheet_name):
    # Rename column's name from vi2en
    replace_columns = {key: val for key, val in VI_TO_EN_COLUMN_NAMES.items() if key in df.columns}
    df = df.rename(columns=replace_columns, inplace=False)

    # Select processor by sheet name
    assert sheet_name in SHEET_NAMES + ['reference'], "Đây không phải là sheet hợp lệ"

    if sheet_name == SHEET_NAMES[0]:
        # Select columns
        df = df[['subject_id', 'program', 'num_of_group', 'room_cap_id']]
        # Drop NaN rows (missing num of class)
        df = df.dropna()
        # Mapping
        df['program'] = df['program'].map(PROGRAM_ID)
        df['room_cap_id'] = df['room_cap_id'].map(ROOM_TYPE_ID)
        df['num_of_group'] = df['num_of_group'].astype(int)

    elif sheet_name == SHEET_NAMES[1]:
        # df = df[df['num_session']]  # loại bỏ tiết thí nghiệm
        df['program'] = df['program'].map(PROGRAM_ID)
        df['day'] = df['day'].astype(int)
        df['session_start'] = df['session_start'].astype(int)

    elif sheet_name == SHEET_NAMES[3]:
        # Select columns
        select_columns = ['subject_id', 'num_session', 'num_of_learning_week', 'midterm_week', 'main_term', 'faculty']
        df = df[select_columns]
        # Drop NaN rows (missing num of class)
        # df = df[df['num_session'] != 0]
    elif sheet_name == 'reference':
        list_weeks = [t for t in df.columns if t[0] == 't' and t[1:].isdigit() and int(t[1:]) <= 18]
        select_columns = ['subject_id', 'group_id', 'num_session', 'teacher_id', 'day', 'session_start', 'room_name']
        select_columns += list_weeks
        df = df[select_columns]
        df = df.rename(columns={t: t.upper() for t in list_weeks}, inplace=False)
        # Loại bỏ các lớp dự thính DT, các lớp CT và các lớp T gì đó
        df = df[[x[:-2] in GROUP_ID_TO_PROGRAM_ID.keys() for x in df['group_id']]]
        df['program'] = df['group_id'].apply(lambda x: GROUP_ID_TO_PROGRAM_ID.get(x[:-2]))
        df = df[(df['day'] != 0) & (df['session_start'] != 0)]
    return df

# data0.to_csv('/Users/twang/Documents/GitHub/Sched/preprocessed/df0-non.csv', index=False)
# data3.to_csv('/Users/twang/Documents/GitHub/Sched/preprocessed/df3-non.csv', index=False)
# data4.to_csv('/Users/twang/Documents/GitHub/Sched/preprocessed/df4-non.csv', index=False)
# ref_data.to_csv('/Users/twang/Documents/GitHub/Sched/preprocessed/refdf-non_preprocessed.csv', index=False)




ref_df = preprocess_raw_data(ref_data, "reference")
ref_df

df0 = preprocess_raw_data(data0, SHEET_NAMES[0])
df0

df0.num_of_group.sum()

df3 = preprocess_raw_data(data3, SHEET_NAMES[3])
df3

df0.merge(df3, on='subject_id').groupby(['num_session'])['num_of_group'].sum()

df4 = preprocess_raw_data(data4, SHEET_NAMES[1])
df4

# df0.to_csv('/Users/vinhvu/Sched/df0_preprocessed.csv', index=False)
# df3.to_csv('/Users/vinhvu/Sched/df3_preprocessed.csv', index=False)
# df4.to_csv('/Users/vinhvu/Sched/df4_preprocessed.csv', index=False)
# ref_df.to_csv('/Users/vinhvu/Sched/refdf_preprocessed.csv', index=False)

"""## Cache Variables"""

############# Untils function ##################
MIN_CAP_ROOM_TYPE_ID = {
    f"{subject_id}-{program}": int(room_cap_id)
    for subject_id, program, room_cap_id in df0[['subject_id', 'program', 'room_cap_id']].itertuples(index=False)
}

NUMBER_OF_SESSION = {
    subject_id: num_session
    for subject_id, num_session in df3[['subject_id', 'num_session']].itertuples(index=False)
}

SUBJECT_ID_TO_NAME = {
    subject_id: subject_name.strip()
    for subject_id, subject_name in data0[['Mã môn học', 'Tên môn học']].itertuples(index=False)
}

SUBJECT_TERM = {
    subject_id: {
        "main_term": main_term,
        "midterm_week": midterm_week
    }
    for subject_id, main_term, midterm_week in df3[['subject_id', 'main_term', 'midterm_week']].itertuples(index=False)
}

SUBJECT_IN_FALCUTY = {
    subject_id: faculty
    for subject_id, faculty in df3[['subject_id', 'faculty']].itertuples(index=False)
}

SUBJECT_INFO = {
    subject_id: {
        "f_dvht": f_dvht,
        "f_ts": f_ts,
        "f_lt": f_lt,
        "f_bt": f_bt,
        'f_tn': f_tn,
        'f_btl': f_btl,
        'f_da': f_da,
        'f_la': f_la,
    }
    for subject_id, f_dvht, f_ts, f_lt, f_bt, f_tn, f_btl, f_da, f_la
    in data2[['Mã MH', 'Tín chỉ', 'Tổng tiết', 'Lý thuyết', 'Bài tập', 'Thí nghiệm', 'BTL', 'DA', 'LA']].itertuples(
        index=False)
}


def get_min_cap_room_type_id(subject_id, group_id):
    program = GROUP_ID_TO_PROGRAM_ID[group_id[:-2]]
    return MIN_CAP_ROOM_TYPE_ID.get(f"{subject_id}-{program}", 1)


TEACHER_IN_SUBJECT_ID = {
    f"{subject_id}-{group_id}": teacher_id
    for subject_id, group_id, teacher_id
    in ref_df[['subject_id', 'group_id', 'teacher_id']].itertuples(index=False)
}

"""# Class GA"""


class CHROMOSOME_GA_BASE:
    pass


GenStruct = namedtuple(
    "GenStruct",
    [
        "subject_id",
        "group_id",
        "day",
        "session_start",
        "room_type_id",
        "weeks_bitstring",
    ], defaults=[None] * 6
)


def parse_gen(gen):
    info_list = gen.split('-')

    # unique tuple attributes
    subject_id = info_list[0]
    group_id = info_list[1]

    # predict attribute
    bitstring = info_list[2]
    day = int(bitstring[0: 3], 2)
    session_start = int(bitstring[3: 7], 2)
    room_type_id = str(int(bitstring[7: 10], 2))
    weeks_bitstring = bitstring[10:]

    return GenStruct(subject_id, group_id, day, session_start, room_type_id, weeks_bitstring)


"""## Chromosome GA Fixed

Hàm `add` là 1 **hàm quan trọng**. Khi khởi tạo `__init__` 1 fixed chromosome từ 1 file đề xuất. Các file đề xuất tiếp theo chỉ cần `add` vào lần lượt theo thứ tự. *Lưu ý: cần bổ sung thêm file dự kiến để cập nhật lại các lớp không cần phải thêm nữa. Hàm sẽ trả về file dự kiến mới với các lớp còn lại cần phải nhờ GA.* Ví dụ:  
Giả sử df4 là file để xuất từ thầy Cường, df5 là file đề xuất từ thầy Dũng (ưu tiên thấp hơn), df0 là file dự kiến và ref_df là file tham khảo từ học kỳ trước.
```
fixed_chromosome = CHROMOSOME_GA_FIXED(df4)
remain_df0 = fixed_chromosome.add(df5, df0)
remain_df0 = fixed_chromosome.add(ref_df, remain_df0)
```
"""


class CHROMOSOME_GA_FIXED(CHROMOSOME_GA_BASE):
    def __init__(self, df0):
        assert all(colname in df0.columns for colname in
                   ['subject_id', 'program', 'group_id', 'num_session', 'day', 'session_start'])
        self.df0 = df0
        self.fixed_classes = []
        self.chromosome = self._generate_parent(df0)

    # Generate random date
    def _generate_parent(self, _df):
        chromosome = []
        for subject_id, program, group_id, num_session, day, session_start in zip(
                _df.subject_id,
                _df.program,
                _df.group_id,
                _df.num_session,
                _df.day,
                _df.session_start,
        ):
            program2 = PROGRAM_ID_TO_GROUP_ID.get(program, "L")
            day = format(day, "03b")
            session_start = format(session_start, "04b")
            if "TN" in program:
                room_type_id = format(3, "03b")
            else:
                room_type_id = format(MIN_CAP_ROOM_TYPE_ID.get(f"{subject_id}-{program}", 1), "03b")  # hiện tại chưa có
            weeks_bitstring = self.get_weeks_bitstring(subject_id, group_id, _df)
            ################# For testing
            if '1' not in weeks_bitstring:
                continue
            #################
            bitstring = "".join([day, session_start, room_type_id, weeks_bitstring])
            # Combine to genes
            genes = "-".join([subject_id, group_id, bitstring])
            chromosome.append(genes)
            self.fixed_classes.append(f"{subject_id}-{group_id}")
        return np.asarray(chromosome)

    def get_weeks_bitstring(self, subject_id, group_id, _df):
        # Filter the DataFrame based on subject_id and group_id
        filtered_df = _df[(_df['subject_id'] == subject_id) & (_df['group_id'] == group_id)]
        # Count the number of 'x' values in T columns
        # x_count = filtered_df.filter(like='T').sum().astype(int)
        list_bits = filtered_df.filter(like='T').eq('x').sum().astype(str).to_list()
        return "".join(list_bits)

    def add(self, _ref_df, _new_df):
        assert all(colname in _ref_df.columns for colname in ['subject_id', 'program', 'group_id', 'num_session', 'day',
                                                              'session_start']), "DataFrame does not contain valid columns"
        assert all(colname in _new_df.columns for colname in
                   ['subject_id', 'program', 'num_of_group']), "DataFrame does not contain valid columns"

        for subject_id, program in _new_df[['subject_id', 'program']].itertuples(index=False):
            # Trong các môn của học kỳ mới, môn nào có một số lớp của học kỳ cũ thì bổ sung vào trước
            sub_new_df = _new_df[(_new_df['subject_id'] == subject_id) & (_new_df['program'] == program)]
            num_of_new_group = sub_new_df['num_of_group'].values[0]

            # Một số lớp đã có trong fixed trước đó rồi
            already_group_exists = self.get_group_ids_by_subject_id(subject_id)
            already_group_exists = [x for x in already_group_exists if x.startswith(PROGRAM_ID_TO_GROUP_ID[program])]

            # Cập nhật lại số lượng lớp cần xử lý
            num_of_new_group -= len(already_group_exists)

            if num_of_new_group > 0:

                ref_df = _ref_df[(_ref_df['subject_id'] == subject_id) & (_ref_df['program'] == program)]

                if num_of_new_group == len(ref_df):  # vừa đủ
                    new_chromosome = self._generate_parent(ref_df)
                    # ???????????????? Cần xét thêm điều kiện mới concatenate
                    self.chromosome = np.concatenate([self.chromosome, new_chromosome])
                    num_of_new_group = 0
                elif num_of_new_group > len(
                        ref_df):  # các lớp ở học kỳ cũ của chương trình này là không đủ lớp với so với học kỳ mới
                    new_chromosome = self._generate_parent(ref_df)
                    self.chromosome = np.concatenate([self.chromosome, new_chromosome])
                    num_of_new_group -= len(ref_df)
                elif num_of_new_group < len(
                        ref_df):  # các lớp ở học kỳ cũ của chương trình này là nhiều hơn lớp với so với học kỳ mới
                    new_chromosome = self._generate_parent(ref_df.sort_values(by='group_id').head(num_of_new_group))
                    self.chromosome = np.concatenate([self.chromosome, new_chromosome])
                    num_of_new_group = 0

            # Cập nhật lại số lớp cần chạy GA phía dưới
            _new_df.loc[sub_new_df.index, 'num_of_group'] = num_of_new_group

        remain_df = _new_df
        return remain_df

    # Mục tiêu của hàm này là lấy danh sách các mã lớp đã có của 1 môn học
    def get_group_ids_by_subject_id(self, subject_id):
        selected_gen = [gen for gen in self.chromosome if gen.startswith(subject_id)]
        return [gen.split('-')[1] for gen in selected_gen]


# Hiển thị file dự kiến ban đâu
display(df0)
# df0.to_csv('/Users/twang/Documents/GitHub/Sched/preprocessed/df0_preprocessed.csv', index=False)
# df3.to_csv('/Users/twang/Documents/GitHub/Sched/preprocessed/df3_preprocessed.csv', index=False)
# df4.to_csv('/Users/twang/Documents/GitHub/Sched/preprocessed/df4_preprocessed.csv', index=False)
# ref_df.to_csv('/Users/twang/Documents/GitHub/Sched/preprocessed/refdf_preprocessed.csv', index=False)
# Sau khi fix 1 file đề xuất đầu tiên
fixed_chromosome = CHROMOSOME_GA_FIXED(df4)
display(fixed_chromosome.chromosome)
print(len(fixed_chromosome.chromosome))
# Tiếp tục là 1 file đề xuất khác (ở đây là chính file tham khảo)
fixed_chromosome_231 = deepcopy(fixed_chromosome)
remain_df0 = fixed_chromosome_231.add(ref_df, df0)
# Số lớp của file dự kiến được cập nhật
display(remain_df0)
display(fixed_chromosome_231.chromosome)
print(len(fixed_chromosome_231.chromosome))
# remain_df0.to_csv('/Users/vinhvu/Sched/remain_df0.csv', index=False)

"""## Chromosome GA"""


class CHROMOSOME_GA(CHROMOSOME_GA_BASE):
    def __init__(self, df0, df1):
        assert all(colname in df0.columns for colname in ['subject_id', 'program', 'num_of_group', 'room_cap_id'])
        assert all(
            colname in df1.columns for colname in ['subject_id', 'num_of_learning_week', 'num_session', 'midterm_week'])
        self.df0 = df0
        self.df1 = df1
        self.chromosome = self._generate_parent

    # Generate random date
    @property
    def _generate_parent(self):
        chromosome = []
        subject_id_same_week_bitstring = {}
        global fixed_chromosome
        for subject_id, program, num_of_group, room_cap_id in zip(
                self.df0.subject_id,
                self.df0.program,
                self.df0.num_of_group,
                self.df0.room_cap_id,
        ):
            program2 = PROGRAM_ID_TO_GROUP_ID.get(program, "L")
            # Một vài mã lớp đã tồn tại ở fixed chromosome rồi, cần đẩy index lên
            exists_group_ids = fixed_chromosome.get_group_ids_by_subject_id(subject_id)
            exists_group_ids = [x for x in exists_group_ids if x.startswith(program2)]
            start_id = len(
                exists_group_ids)  # !!!!! giả sử các lớp trước đã sort rồi nhé, ví dụ có 2 lớp thì phải là L01, L02 hoặc CC01, CC02
            group_ids = [f"{program2}{(i + 1):02d}" for i in
                         range(start_id, start_id + num_of_group)]  # L01, L02, CC01, CC02, CN01
            for group_id in group_ids:
                ############# Trong trường hợp các lớp đã fixed trước, bỏ qua ############
                if f"{subject_id}-{group_id}" in fixed_chromosome.fixed_classes:
                    continue
                #########################################################################################
                day = format(random.randint(VALID_DAY.start, VALID_DAY.stop - 1), "03b")
                session_start = format(random.randint(VALID_SESSION_START.start, VALID_SESSION_START.stop - 1), "04b")
                room_type_id = format(int(room_cap_id), "03b")
                weeks_require = self.get_num_of_weeks_require(subject_id)
                if weeks_require == 0:
                    continue

                weeks_bitstring = subject_id_same_week_bitstring.get(subject_id,
                                                                     self.random_weeks_bitstring(weeks_require,
                                                                                                 subject_id))
                subject_id_same_week_bitstring[subject_id] = weeks_bitstring
                ################# For testing
                if '1' not in weeks_bitstring:
                    continue
                #################
                bitstring = "".join([day, session_start, room_type_id, weeks_bitstring])
                # Combine to genes
                genes = "-".join([subject_id, group_id, bitstring])
                chromosome.append(genes)
        return np.asarray(chromosome)

    def random_weeks_bitstring(self, K, subject_id):
        if K == 0:
            return "0" * MAX_ACTIVE_WEEKS
        midterm = SUBJECT_TERM[subject_id]['midterm_week']
        if K >= 7:  # môn lý thuyết
            # học full 6 tuần đầu, nghỉ 1 trong 2 tuần 7 và 8, học các tuần còn lại
            k = round(K)
            return '1' * 6 + random.choice(["01", '10']) + '1' * (k - 7) + '0' * (MAX_ACTIVE_WEEKS - k - 1)
        else:  # môn thí nghiệm
            # TODO: tính toán sau, bên dưới chỉ đề đỡ
            # 6 bit đầu là 0, 12 bit sau sẽ là K số 1 random xen kẽ
            bitstring = '0' * 5
            remaining_bits = MAX_ACTIVE_WEEKS - 5

            bit_list = ['0'] * (remaining_bits)

            # Place ones randomly in the remaining 12 bits
            for i in range(random.choice([0, 1]), remaining_bits, 2):
                if K > 0:
                    bit_list[i] = '1'
                    K -= 1

            # Convert list back to string
            bitstring += ''.join(bit_list[:13])

            return bitstring

    def get_num_of_weeks_require(self, _subject_id):
        for subject_id, num_of_learning_week in self.df1[['subject_id', 'num_of_learning_week']].itertuples(
                index=False):
            if subject_id == _subject_id:
                return num_of_learning_week
        print(_subject_id)


chromosome = CHROMOSOME_GA(remain_df0, df3)
chromosome.chromosome

"""# Class Struct & Class Dict Global

Mục đích sau cùng của các utils function là hard dữ liệu. Vì vậy, với bộ dữ liệu thực tế, chúng ta thay đổi các tác vụ load data để sau cùng thống nhất về `ClassDictGlobal` để truy xuất trên RAM/Cache nhanh nhất
"""

ClassStruct = namedtuple(
    "ClassStruct",
    [
        "subject_id",
        "group_id",
        "subject_name",
        "min_capable_room_type_id",
        "num_of_session",
        "program",
        "teacher_id",
        "num_of_learning_week",
        "midterm_week",
        "facility",
        "faculty",
        "main_term"
    ], defaults=["", "", "", 1, 2, "CQ", "", 15, 0, "DAn", "CS", 3]
)

ClassDictGlobal = {}
for gen in np.concatenate((chromosome.chromosome, fixed_chromosome.chromosome)):
    info = parse_gen(gen)
    class_struct = {
        "subject_id": info.subject_id,
        "group_id": info.group_id,
        "subject_name": SUBJECT_ID_TO_NAME[info.subject_id],
        "min_capable_room_type_id": get_min_cap_room_type_id(info.subject_id, info.group_id),
        "num_of_session": NUMBER_OF_SESSION[info.subject_id],
        "program": GROUP_ID_TO_PROGRAM_ID[info.group_id[:-2]],
        "facility": FACILITY[PROGRAM_ID_TO_GROUP_ID[GROUP_ID_TO_PROGRAM_ID[info.group_id[:-2]]]],
        "faculty": SUBJECT_IN_FALCUTY.get(info.subject_id, "CS"),
        "main_term": SUBJECT_TERM.get(info.subject_id, {}).get("main_term", 3),
        "midterm_week": SUBJECT_TERM.get(info.subject_id, {}).get("midterm_week", 7),
        "teacher_id": TEACHER_IN_SUBJECT_ID.get(f"{info.subject_id}-{info.group_id}",
                                                f"{info.subject_id}_{random.randint(1, 4):02}")
    }
    ClassDictGlobal[f"{info.subject_id}-{info.group_id}"] = ClassStruct(**class_struct)

ClassDictGlobal

"""# GA Algorithm"""

def repair_day(gen):
    info = parse_gen(gen)
    if info.day not in VALID_DAY:
        day = random.choice(VALID_DAY)
        new_bitstring = format(day, "03b") + format(info.session_start, "04b") + format(int(info.room_type_id), "03b") + info.weeks_bitstring
        new_gen = "-".join([info.subject_id, info.group_id, new_bitstring])
        return new_gen
    return gen
def repair_room_type_id(gen):
    info = parse_gen(gen)
    if '(tn)' in SUBJECT_ID_TO_NAME.get(info.subject_id) and info.room_type_id not in ["1", "2"]:
        room_type_id = random.choice(["1", "2"])  # Chọn ngẫu nhiên giữa "1" và "2"
        new_bitstring = format(info.day, "03b") + format(info.session_start, "04b") + format(int(room_type_id),
                                                                                             "03b") + info.weeks_bitstring
        new_gen = "-".join([info.subject_id, info.group_id, new_bitstring])
        return new_gen
    if '(tn)' not in SUBJECT_ID_TO_NAME.get(info.subject_id) and info.room_type_id not in [str(r) for r in range(3, 9)]:
        room_type_id = random.choice([str(r) for r in range(3, 9)])
        new_bitstring = format(info.day, "03b") + format(info.session_start, "04b") + format(int(room_type_id),
                                                                                             "03b") + info.weeks_bitstring
        new_gen = "-".join([info.subject_id, info.group_id, new_bitstring])
        return new_gen
    if info.room_type_id not in VALID_ROOM_TYPE_ID:
        if '(tn)' in SUBJECT_ID_TO_NAME.get(info.subject_id):
            room_type_id = random.choice(["1", "2"])  # Chọn ngẫu nhiên giữa "1" và "2"
            new_bitstring = format(info.day, "03b") + format(info.session_start, "04b") + format(int(room_type_id),
                                                                                                 "03b") + info.weeks_bitstring
            new_gen = "-".join([info.subject_id, info.group_id, new_bitstring])
            return new_gen
        if '(tn)' not in SUBJECT_ID_TO_NAME.get(info.subject_id):
            room_type_id = random.choice([str(r) for r in range(3, 9)])
            new_bitstring = format(info.day, "03b") + format(info.session_start, "04b") + format(int(room_type_id),
                                                                                                 "03b") + info.weeks_bitstring
            new_gen = "-".join([info.subject_id, info.group_id, new_bitstring])
            return new_gen
    return gen


# Hàm sửa lỗi cho toàn bộ quần thể
def repair_population(population):
    for ind in population:
        for idx_gen, gen in enumerate(ind.chromosome):
            ind.chromosome[idx_gen] = repair_day(repair_room_type_id(gen))
    return population


############# GA Module ##################


def init_population(data0, data1, size_of_population):
    new_population = []
    for i in range(size_of_population):
        new_individual = CHROMOSOME_GA(data0, data1)
        new_population.append(new_individual)
    new_population = repair_population(new_population)
    return np.asarray(new_population)


def select_mating_pool(population, fitness_list, elitism_size):
    sorted_indices = np.argsort(fitness_list)
    mating_pool = population[sorted_indices[:elitism_size]]
    return mating_pool


def crossover(parents, lower_threshold=[0.3, 0.1, 0.5, 0.3]):
    offsprings = []
    while len(offsprings) < len(parents):
        parent_1, parent_2 = random.sample(list(parents), 2)
        child_1, child_2 = deepcopy(parent_1), deepcopy(parent_2)
        chromosome_swap_index = random.randrange(len(parent_1.chromosome))
        parent_1_str = str(parent_1.chromosome[chromosome_swap_index])
        parent_2_str = str(parent_2.chromosome[chromosome_swap_index])
        parent_1_components = parent_1_str.split("-")
        parent_2_components = parent_2_str.split("-")
        constant_attrs_1, bitstring_1 = parent_1_components[:-1], parent_1_components[-1]
        constant_attrs_2, bitstring_2 = parent_2_components[:-1], parent_2_components[-1]
        offspring_1 = "-".join(constant_attrs_1) + "-"
        offspring_2 = "-".join(constant_attrs_2) + "-"
        range_index = [(0, 3), (3, 7), (7, 10), (10, len(bitstring_1))]
        for (s, e), thresh in zip(range_index, lower_threshold):
            if random.random() > thresh:
                offspring_1 += bitstring_2[s:e]
                offspring_2 += bitstring_1[s:e]
            else:
                offspring_1 += bitstring_1[s:e]
                offspring_2 += bitstring_2[s:e]
        child_1.chromosome[chromosome_swap_index] = np.str_(repair_day(repair_room_type_id(offspring_1)))
        child_2.chromosome[chromosome_swap_index] = np.str_(repair_day(repair_room_type_id(offspring_2)))
        offsprings.append(child_1)
        offsprings.append(child_2)
    return np.array(offsprings)


def mutation(population, mutation_rate, lower_threshold=[0.5, 0.1, 0.7, 0.5]):
    offsprings = deepcopy(population)
    for chromosome in offsprings:
        for idx, gen in enumerate(chromosome.chromosome):
            if random.uniform(0, 1) < mutation_rate:
                start_bitstring_index = gen.rfind("-") + 1
                range_index = [(0, 3), (3, 7), (7, 10), (10, len(gen.split('-')[-1]))]
                for (s, e), thresh in zip(range_index, lower_threshold):
                    if random.random() > thresh:
                        mut_idx = start_bitstring_index + random.randrange(s, e)
                        gen = gen[:mut_idx] + str(random.randint(0, 1)) + gen[mut_idx + 1:]
                chromosome.chromosome[idx] = repair_room_type_id(gen)
    return np.asarray(offsprings)


def selection(chromosomes, fitness_results, population_size, elitism_size):
    combined_data = list(zip(chromosomes, fitness_results))
    sorted_data = sorted(combined_data, key=lambda x: x[1])
    elite_individuals = [data[0] for data in sorted_data[:elitism_size]]
    remaining_individuals = [data[0] for data in sorted_data[elitism_size:]]
    if len(remaining_individuals) < (population_size - elitism_size):
        selected_individuals = elite_individuals + remaining_individuals
    else:
        selected_individuals = elite_individuals + random.sample(remaining_individuals, population_size - elitism_size)
    fitness_list = [tracking_chromosome_fitness(merge_with_fixed_chromosome(ind))['fitness'] for ind in
                    selected_individuals]
    return np.asarray(selected_individuals), np.asarray(fitness_list)


"""## GA Constraints

### Constraints Type

**Lưu ý**, xem thật kỹ `class ConstraintBase`, các ràng buộc đều phải kế thừa class này cũng như tên class mới phải `endswith("Constraint")`
"""


class ConstraintTypeBase:
    pass


class ConstraintTypeSoft(ConstraintTypeBase):
    penalty = 5


class ConstraintTypeHard(ConstraintTypeBase):
    penalty = 10


# Với các lỗi về invalid constraint, GA sẽ optimize để dần giảm thiếu hóa các lỗi này trước, sau khi các lỗi này giảm, các lỗi khác Invalid sẽ bắt đầu được xét

class ConstraintBase:
    InvalidIndices = []

    def __init__(self, _name: str, _type: ConstraintTypeBase):
        self.type = _type
        self.name = _name  # Tên của ràng buộc
        self.active = True  # Nếu không xét đến Constraint thì đổi về False

        self.penalty = {
            ConstraintTypeSoft: ConstraintTypeSoft.penalty,
            ConstraintTypeHard: ConstraintTypeHard.penalty
        }.get(type(_type), 0)

        self.vars_depend = ""  # "day", "session_start", "room_type_id", "weeks_bitstring"

    def __call__(self, chromosome):
        pass

    @property
    def fitness(self):
        return 0


"""### Invalid Constraints"""


class InvalidDayConstraint(ConstraintBase):
    def __init__(self):
        super().__init__("Invalid Day", ConstraintTypeHard())
        self._logging = defaultdict(int)
        self.vars_depend = "day"
        self.penalty = 100

    def __call__(self, chromosome):
        for idx, gen in enumerate(chromosome.chromosome):
            info = parse_gen(gen)
            if info.day not in VALID_DAY:
                self._logging['invalid_day_cases'] += 1
                ConstraintBase.InvalidIndices.append(idx)
        return self._logging

    @property
    def fitness(self):
        return sum(self._logging.values()) * self.penalty


class InvalidSessionConstraint(ConstraintBase):
    def __init__(self):
        super().__init__("Invalid Session", ConstraintTypeHard())
        self.active = True
        self._logging = defaultdict(int)
        self.vars_depend = "session_start"
        self.penalty = 200

    def __call__(self, chromosome):
        for idx, gen in enumerate(chromosome.chromosome):
            info = parse_gen(gen)

            duration = NUMBER_OF_SESSION[info.subject_id]

            self._logging['total_invalid_session_cases'] += 1  # if no case error, minus 1 later
            ConstraintBase.InvalidIndices.append(idx)
            if info.session_start not in VALID_SESSION_START:
                self._logging['invalid_start_session'] += 1
            elif info.session_start + duration not in VALID_SESSION:
                self._logging['invalid_end_session'] += 1
            else:  # no case error, minus 1
                self._logging['total_invalid_session_cases'] -= 1
                ConstraintBase.InvalidIndices = ConstraintBase.InvalidIndices[:-1]

        return self._logging

    @property
    def fitness(self):
        return sum(self._logging.values()) * self.penalty


class InvalidRoomTypeIdConstraint(ConstraintBase):
    def __init__(self):
        super().__init__("Invalid Room Type Id", ConstraintTypeHard())
        self.active = True
        self._logging = defaultdict(int)
        self.invalid_room_type_id_cases = 10
        self.vars_depend = "room_type_id"

    def __call__(self, chromosome):
        for idx, gen in enumerate(chromosome.chromosome):
            info = parse_gen(gen)
            if "(tn)" in info.subject_id and info.room_type_id not in ["1", "2"]:
                self._logging['invalid_room_type_id_cases'] += 99999999999
                ConstraintBase.InvalidIndices.append(idx)
            if info.room_type_id not in VALID_ROOM_TYPE_ID:
                self._logging['invalid_room_type_id_cases'] += 1
                ConstraintBase.InvalidIndices.append(idx)
        return self._logging

    @property
    def fitness(self):
        return sum(self._logging.values()) * self.penalty


"""### Room Constraints"""


class SmallerRoomConstraint(ConstraintBase):
    def __init__(self):
        super().__init__("Smaller Room", ConstraintTypeSoft())
        self.active = True
        self._logging = defaultdict(int)
        self.vars_depend = "room_type_id"

    def __call__(self, chromosome):
        for idx, gen in enumerate(chromosome.chromosome):
            if idx in ConstraintBase.InvalidIndices:
                continue
            info = parse_gen(gen)
            if int(info.room_type_id) < int(get_min_cap_room_type_id(info.subject_id, info.group_id)):
                self._logging['smaller_room'] += 1

        return self._logging

    @property
    def fitness(self):
        return sum(self._logging.values()) * self.penalty


class OverloadRoomConstraint(ConstraintBase):
    def __init__(self):
        super().__init__("Overload Room", ConstraintTypeSoft())
        self.active = False
        self._logging = defaultdict(int)
        self.vars_depend = "room_type_id"

    def __call__(self, chromosome):
        time_loc_dict = defaultdict(int)

        for idx, gen in enumerate(chromosome.chromosome):
            if idx in ConstraintBase.InvalidIndices:
                continue
            info = parse_gen(gen)

            duration = NUMBER_OF_SESSION[info.subject_id]
            facility = FACILITY[info.group_id[
                                :-2]]  # get value of key (L or CC or CN) because the 2 last letter is number of group like 01, 02
            for idx, bit in enumerate(info.weeks_bitstring):
                if bit == '1':
                    for session in range(info.session_start, info.session_start + duration):
                        key = f"{idx + 1}-{info.day}-{session}-{facility}-{info.room_type_id}"
                        time_loc_dict[key] += 1

        for key, _count in time_loc_dict.items():
            facility, room_type_id = key.split('-')[-2:]
            try:
                if _count > NUMBER_OF_ROOM[f"{facility}-{room_type_id}"]:
                    self._logging['overload_room_cases'] += 1
            except:
                self._logging['invalid_cases'] += 1

        return self._logging

    @property
    def fitness(self):
        return sum(self._logging.values()) * self.penalty


"""### Teacher Constraints"""


class TakeABreakConstraint(ConstraintBase):
    def __init__(self):
        super().__init__("Take A Break", ConstraintTypeSoft())
        self.active = True
        self.vars_depend = "session_start"
        self._logging = defaultdict(int)
        self.penalty = 10

    def __call__(self, chromosome):
        time_loc_dict = defaultdict(int)

        for idx, gen in enumerate(chromosome.chromosome):
            if idx in ConstraintBase.InvalidIndices:
                continue
            info = parse_gen(gen)

            if info.session_start == 7:
                self._logging['not_break_at_lunch_cases'] += 1

        return self._logging

    @property
    def fitness(self):
        return sum(self._logging.values()) * self.penalty


class NumberTeacherRequireConstraint(ConstraintBase):
    """

    """

    def __init__(self):
        super().__init__("Number Teacher Require", ConstraintTypeHard())
        self.active = False

    def __call__(self, chromosome):
        for idx, gen in enumerate(chromosome.chromosome):
            if idx in ConstraintBase.InvalidIndices:
                continue
            info = parse_gen(gen)
            attributes = ClassDictGlobal[f"{info.subject_id}-{info.group_id}"]

    @property
    def fitness(self):
        return self.overlap_cases * self.penalty


class TeacherStayAtFacilityConstraint(ConstraintBase):
    """
    Mỗi ngày, giảng viên chỉ giảng dạy tại 1 cơ sở
    """

    def __init__(self):
        super().__init__("Teacher Stay At Facility", ConstraintTypeSoft())
        self.active = True
        self._logging = defaultdict(int)

    def __call__(self, chromosome):
        # dict[Week-Day] = { Facility1 : [Teacher1, Teacher2, Teacher3], Facility2 : [Teacher1, Teacher4, Teacher5]}
        _dict = defaultdict(lambda: defaultdict(list))
        for idx, gen in enumerate(chromosome.chromosome):
            if idx in ConstraintBase.InvalidIndices:
                continue
            info = parse_gen(gen)
            attributes = ClassDictGlobal[f"{info.subject_id}-{info.group_id}"]
            for idx, bit in enumerate(info.weeks_bitstring):
                if bit == '1':
                    _dict[f"{idx + 1}-{info.day}"][attributes.facility] += [attributes.teacher_id]
        for _, facilities in _dict.items():
            if len(facilities) == 1:  # just 1 facility is working at this day
                continue
            # list teacher_ids in each facility
            teacher_ids = facilities.values()
            # Map to set
            sets = [set(lst) for lst in teacher_ids]
            # Find intersection
            teacher_id_intersection = set.intersection(*sets)
            self._logging['num_teacher_two_facilities'] += len(teacher_id_intersection)
        return self._logging

    @property
    def fitness(self):
        return sum(self._logging.values()) * self.penalty


"""### Week Learning Constraints"""


class SubjectSameMainTermConstraint(ConstraintBase):
    """
    Các môn học của cùng 1 học kỳ chính (theo sơ đồ đào tạo) không nên diễn ra trùng nhau, để sinh viên có nhiều lựa chọn TKB phù hợp
    Các lớp học có cùng mã môn có thể diễn ra cùng thời điểm (phụ thuộc vào số lượng giảng viên của môn). Tham khảo class NumberTeacherRequireConstraint
    """

    def __init__(self):
        super().__init__("Subject Same Main Term", ConstraintTypeSoft())
        self.active = True
        self._logging = defaultdict(int)
        self.vars_depend = "session_start"
        self.penalty = 10

    def __call__(self, chromosome):
        # For all class (=tuple(subject_id, group_id)), group them by facility, faculty, main_term
        # e.g dict["DAn-CS-3"] = [object(CO2003,L01), object(CO2003, L02), object(CO2007, L01)]
        subject_same_term_in_week = defaultdict(list)
        for idx, gen in enumerate(chromosome.chromosome):
            if idx in ConstraintBase.InvalidIndices:
                continue
            info = parse_gen(gen)
            attributes = ClassDictGlobal[f"{info.subject_id}-{info.group_id}"]
            _key = f"{attributes.facility}-{attributes.faculty}-{attributes.main_term}"
            subject_same_term_in_week[_key].append(info)

        # e.g dict["Monday-2"] = [CO2003, CO2007]
        time_points = defaultdict(list)
        for classes in subject_same_term_in_week.values():
            for _class in classes:  # type(_class) is GenStruct
                day = _class.day
                # parse learning sessions to unit session
                duration = NUMBER_OF_SESSION[_class.subject_id]
                for session in range(_class.session_start, _class.session_start + duration):
                    time_points[f"{day}-{session}"].append(f"{_class.subject_id}-{_class.group_id}")

        # List all combinations between 2 different subject_ids at the same timepoint
        overlap_classes = []
        for classes in time_points.values():
            _combinations = list(combinations(classes, 2))
            _combinations = [x for x in _combinations if x[0].split('-')[0] != x[1].split('-')[0]]  # CO2003 != CO2007
            overlap_classes += _combinations

        self._logging['overlap_classes_mainterm'] = len(overlap_classes) // 18

        return self._logging

    @property
    def fitness(self):
        return sum(self._logging.values()) * self.penalty


# Các môn cùng mã môn nên có thời khóa biểu tuần học giống nhau
class SameLearningWeekConstraint(ConstraintBase):
    def __init__(self):
        super().__init__("Same Learning Week", ConstraintTypeHard())
        self._logging = defaultdict(int)
        self.vars_depend = "week"
        self.penalty = 50

    def __call__(self, chromosome):
        subjects = defaultdict(list)
        for idx, gen in enumerate(chromosome.chromosome):
            info = parse_gen(gen)
            subjects[info.subject_id].append(info.weeks_bitstring)
        for subject_id, calendars in subjects.items():
            _combinations = list(combinations(calendars, 2))
            self._logging["same_subject_not_same_week"] += sum(1 if x[0] != x[1] else 0 for x in _combinations)
        return self._logging

    @property
    def fitness(self):
        return sum(self._logging.values()) * self.penalty


class MidTermOccurConstraint(ConstraintBase):
    def __init__(self):
        super().__init__("Kiểm tra tuần thi giữa kỳ các môn", ConstraintTypeHard())
        self._logging = defaultdict(int)
        self.active = False
        self.vars_depend = "week"
        self.penalty = 50

    def __call__(self, chromosome):
        for idx, gen in enumerate(chromosome.chromosome):
            info = parse_gen(gen)
            # TODO
        return self._logging

    @property
    def fitness(self):
        return sum(self._logging.values()) * self.penalty


lab_room_cc_cn = {
    "102-C6": ["CO3094", "CO2014", "CO2004", "CO2018", "CO1006"],
    "103-C6": ["CO3094", "CO2014", "CO2004", "CO2018", "CO1006"],
    "104-C6": ["CO3094", "CO2014", "CO2004", "CO2018", "CO1006"],
    "509-C6": ["CO3094", "CO2014", "CO2004", "CO2018", "CO1006"],
    "202-C5": ["CO2008", "CO1024", "CO3010", "CO2038"],
    "105-C6": ["CO3054", "CO1024", "CO3010", "CO2038"]
}

lab_room_l = {
    "701-H6": ["CO2014", "CO2004", "CO2018", "CO1006"],
    "702-H6": ["CO2014", "CO2004", "CO2018", "CO1006"],
    "703-H6": ["CO2014", "CO2004", "CO2018", "CO1006"],
    "707-H6": ["CO2014", "CO2004", "CO2018", "CO1006"],
    "603-H6": ["CO2014", "CO2004", "CO2018", "CO1006"],
    "604-H6": ["CO2014", "CO2004", "CO2018", "CO1006"],
    "601-H6": ["CO2008", "CO3054", "CO3010", "CO1024", "CO2038"],
    "605-H6": ["CO1024", "CO2038"],
    "708-H6": ["CO3094"],
}

class LabRoomConstraint(ConstraintBase):
    def __init__(self):
        super().__init__("Lab Invalid Room", ConstraintTypeHard())
        self.active = True
        self._logging = defaultdict(int)
        self.vars_depend = "lab"
        self.penalty = 500  # Tăng hệ số phạt cho ràng buộc phòng thí nghiệm
        self.lab_room_dict_cc_cn = self.create_lab_room_dict(lab_room_cc_cn)
        self.lab_room_dict_l = self.create_lab_room_dict(lab_room_l)

    def create_lab_room_dict(self, lab_room):
        lab_room_dict = defaultdict(list)
        for room, subject_codes in lab_room.items():
            for subject_code in subject_codes:
                lab_room_dict[subject_code].append(room)
        return lab_room_dict

    def __call__(self, chromosome):
        day_sessions = defaultdict(lambda: defaultdict(lambda: defaultdict(list)))
        for idx, gen in enumerate(chromosome.chromosome):
            info = parse_gen(gen)
            if "tn" in SUBJECT_ID_TO_NAME.get(info.subject_id, "").lower():
                group_type = info.group_id[:2]  # Giả sử "CC" hoặc "CN" hoặc "L" nằm ở đầu
                day_sessions[group_type][info.day][info.session_start].append(info.subject_id)

        for group_type, days in day_sessions.items():
            for day, sessions in days.items():
                for session_start, subjects in sessions.items():
                    if group_type in ["CC", "CN"]:
                        self.check_lab_rooms(subjects, self.lab_room_dict_cc_cn, group_type, day, session_start)
                    elif group_type == "L":
                        self.check_lab_rooms(subjects, self.lab_room_dict_l, group_type, day, session_start)
                    else:
                        # Handle other group types if necessary
                        pass

        return self._logging

    def check_lab_rooms(self, subjects, lab_room_dict, group_type, day, session_start):
        rooms_used = defaultdict(int)
        for subject in subjects:
            if subject in lab_room_dict:
                for room in lab_room_dict[subject]:
                    rooms_used[room] += 1

        for room, count in rooms_used.items():
            if count > 1:
                self._logging[f'invalid_lab_room_group_{group_type}_day_{day}_session_{session_start}'] += 1
                # Ghi nhật ký chi tiết
                print(f"Violation found: {group_type} on day {day} at session {session_start} in room {room} with count {count}")

    @property
    def fitness(self):
        return sum(self._logging.values()) * self.penalty





"""### Constraints Manager"""


def get_all_constraints() -> list:
    constraints = [(name, obj()) for name, obj in globals().items() if
                   name.endswith("Constraint") and isinstance(obj, type) and issubclass(obj,
                                                                                        ConstraintBase) and obj().active]
    return constraints


def repair_room_type_id(gen):
    info = parse_gen(gen)
    if '(tn)' in SUBJECT_ID_TO_NAME.get(info.subject_id) and info.room_type_id not in ["1", "2"]:
        room_type_id = random.choice(["1", "2"])  # Chọn ngẫu nhiên giữa "1" và "2"
        new_bitstring = format(info.day, "03b") + format(info.session_start, "04b") + format(int(room_type_id),
                                                                                             "03b") + info.weeks_bitstring
        new_gen = "-".join([info.subject_id, info.group_id, new_bitstring])
        return new_gen
    if '(tn)' not in SUBJECT_ID_TO_NAME.get(info.subject_id) and info.room_type_id not in [str(r) for r in range(3, 9)]:
        room_type_id = random.choice([str(r) for r in range(3, 9)])
        new_bitstring = format(info.day, "03b") + format(info.session_start, "04b") + format(int(room_type_id),
                                                                                             "03b") + info.weeks_bitstring
        new_gen = "-".join([info.subject_id, info.group_id, new_bitstring])
        return new_gen
    if info.room_type_id not in VALID_ROOM_TYPE_ID:
        if '(tn)' in SUBJECT_ID_TO_NAME.get(info.subject_id):
            room_type_id = random.choice(["1", "2"])  # Chọn ngẫu nhiên giữa "1" và "2"
            new_bitstring = format(info.day, "03b") + format(info.session_start, "04b") + format(int(room_type_id),
                                                                                                 "03b") + info.weeks_bitstring
            new_gen = "-".join([info.subject_id, info.group_id, new_bitstring])
            return new_gen
        if '(tn)' not in SUBJECT_ID_TO_NAME.get(info.subject_id):
            room_type_id = random.choice([str(r) for r in range(3, 9)])
            new_bitstring = format(info.day, "03b") + format(info.session_start, "04b") + format(int(room_type_id),
                                                                                                 "03b") + info.weeks_bitstring
            new_gen = "-".join([info.subject_id, info.group_id, new_bitstring])
            return new_gen
    return gen


def tracking_chromosome_fitness(chromosome):
    fitness = 0
    error_cases = {}
    vars_depend_fitness = defaultdict(int)
    active_constraints = []
    ConstraintBase.InvalidIndices = []
    repaired_chromosome = deepcopy(chromosome)

    # Apply repair function to each gen
    for idx, gen in enumerate(repaired_chromosome.chromosome):
        repaired_chromosome.chromosome[idx] = repair_room_type_id(gen)

    for constraint_name, constraint_func in get_all_constraints():
        active_constraints.append(constraint_name)
        for key, value in constraint_func(repaired_chromosome).items():
            if key in error_cases:
                error_cases[key] += value
            else:
                error_cases[key] = value
        fitness += constraint_func.fitness
        vars_depend_fitness[constraint_func.vars_depend] += constraint_func.fitness

    return {
        "fitness": fitness,
        "error_cases": error_cases,
        "vars_depend_fitness": vars_depend_fitness,
        "active_constraints": active_constraints,
    }


tracking_chromosome_fitness(chromosome)

# Kiểm tra xem các lớp đã fixed trước đó có bị overlap hay invalid không
tracking_chromosome_fitness(fixed_chromosome)

"""# Train GA"""


# num_generations = 1
# population_size = 20
#
# mating_rate = 0.6
# crossover_rate = 0.8
# mutation_rate = 0.3


# Hàm này dùng để tăng khả năng mutation cũng như crossover đặc biệt cho các đoạn gen cần thiết để giảm fitness cho toàn bộ invidual,
# tuy nhiên, kết quả thực nghiệm cho thấy, tập trung thay đổi vào 1 trường dữ liệu ko tạo ra biến thể tốt,
# vì các trường ko phải hoàn toàn độc lập
def generate_lower_threshold(vars_depend_fitness: list):
    vars_depend_fitness = np.array(vars_depend_fitness).astype(float)
    vars_depend_fitness /= np.sum(vars_depend_fitness)
    vars_depend_fitness = [min(max(x, 0.1), 0.9) for x in vars_depend_fitness]
    vars_depend_fitness = [1 - x for x in vars_depend_fitness]
    return vars_depend_fitness


# generate_lower_threshold([0, 0, 50, 0])

# Sau khi GA, kết hợp population với từng fixed_chromosome để đánh giá kết quả toàn cục
def merge_with_fixed_chromosome(chromosome):
    global fixed_chromosome
    merged_chromosome = deepcopy(chromosome)
    merged_chromosome.chromosome = np.concatenate((fixed_chromosome.chromosome, merged_chromosome.chromosome))
    return merged_chromosome

def merge_with_fixed_chromosome_and231(chromosome):
    global fixed_chromosome_231
    merged_chromosome = deepcopy(chromosome)
    merged_chromosome.chromosome = np.concatenate((fixed_chromosome_231.chromosome, merged_chromosome.chromosome))
    return merged_chromosome


def periodic_restart(population, data0, data1, restart_threshold, generation):
    if generation % restart_threshold == 0:
        new_population = init_population(data0, data1, len(population))
        population[:len(new_population) // 2] = new_population[:len(new_population) // 2]
        population = repair_population(population)
    return population


def adaptive_mutation(population, base_mutation_rate, generation, max_generations):
    mutation_rate = base_mutation_rate * (1 - generation / max_generations)
    offsprings = mutation(population, mutation_rate)
    for idx, ind in enumerate(offsprings):
        for idx_gen, gen in enumerate(ind.chromosome):
            ind.chromosome[idx_gen] = repair_day(repair_room_type_id(gen))
    return offsprings


# def repair_population(population):
#     for ind in population:
#         for idx_gen, gen in enumerate(ind.chromosome):
#             ind.chromosome[idx_gen] = repair_room_type_id(gen)
#     return population

# Sửa chữa quần thể trước khi đánh giá fitness
# def train_ga_with_strategies(data0, data1, num_generations=100, population_size=100, elitism_size=10,
#                              mating_rate=0.7, crossover_rate=0.8, base_mutation_rate=0.2, restart_threshold=50):
#     population = init_population(data0, data1, population_size)
#     population = repair_population(population)
#
#     fitness_list = [tracking_chromosome_fitness(merge_with_fixed_chromosome(ind))['fitness'] for ind in population]
#     best_fitness = min(fitness_list)
#     best_chromosome = population[np.argmin(fitness_list)]
#     global_logging = []
#
#     for gen_idx in tqdm(range(num_generations)):
#         parents = select_mating_pool(population, fitness_list, elitism_size)
#         offspring_crossover = crossover(parents)
#         offspring_mutation = adaptive_mutation(offspring_crossover, base_mutation_rate, gen_idx, num_generations)
#         total_population = np.concatenate((parents, offspring_crossover, offspring_mutation))
#         total_population = periodic_restart(total_population, data0, data1, restart_threshold, gen_idx)
#
#         total_population = repair_population(total_population)
#
#         fitness_results = [tracking_chromosome_fitness(merge_with_fixed_chromosome(ind))['fitness'] for ind in total_population]
#         population, fitness_list = selection(total_population, fitness_results, population_size, elitism_size)
#
#         population = repair_population(population)
#
#         current_best_fitness = min(fitness_list)
#         current_best_chromosome = population[np.argmin(fitness_list)]
#         if current_best_fitness < best_fitness:
#             best_fitness = current_best_fitness
#             best_chromosome = current_best_chromosome
#
#         print(f"Generation {gen_idx} | Best Fitness: {best_fitness}")
#         global_logging.append({
#             'generation': gen_idx,
#             'best_fitness': best_fitness,
#             'fitness_list': fitness_list
#         })
#         if best_fitness == 0:
#             break
#
#     return best_chromosome, global_logging

# Call the train_ga_with_strategies function with appropriate parameters
def train_ga_with_strategies(data0, data1, num_generations=100, population_size=100, elitism_size=10,
                             mating_rate=0.7, crossover_rate=0.8, base_mutation_rate=0.2, restart_threshold=50):
    population = init_population(data0, data1, population_size)
    population = repair_population(population)
    fitness_list = [tracking_chromosome_fitness(merge_with_fixed_chromosome(ind))['fitness'] for ind in population]
    best_fitness = min(fitness_list)
    best_chromosome = population[np.argmin(fitness_list)]
    global_logging = []

    for gen_idx in tqdm(range(num_generations)):
        parents = select_mating_pool(population, fitness_list, elitism_size)
        offspring_crossover = crossover(parents)
        offspring_mutation = adaptive_mutation(offspring_crossover, base_mutation_rate, gen_idx, num_generations)
        total_population = np.concatenate((parents, offspring_crossover, offspring_mutation))
        total_population = repair_population(total_population)
        total_population = periodic_restart(total_population, data0, data1, restart_threshold, gen_idx)
        total_population = repair_population(total_population)

        fitness_results = [tracking_chromosome_fitness(merge_with_fixed_chromosome(ind))['fitness'] for ind in
                           total_population]
        population, fitness_list = selection(total_population, fitness_results, population_size, elitism_size)
        population = repair_population(population)

        current_best_fitness = min(fitness_list)
        current_best_chromosome = population[np.argmin(fitness_list)]
        if current_best_fitness < best_fitness:
            best_fitness = current_best_fitness
            best_chromosome = current_best_chromosome

        print(f"Generation {gen_idx} | Best Fitness: {best_fitness}")
        global_logging.append({
            'generation': gen_idx,
            'best_fitness': best_fitness,
            'fitness_list': fitness_list
        })
        if best_fitness == 0:
            break

    return best_chromosome, global_logging


# Call the train_ga_with_strategies function with appropriate parameters
best_chromosome, global_logging = train_ga_with_strategies(
    df0, df3,
    num_generations=100,  # Tăng số thế hệ
    population_size=150,  # Tăng kích thước quần thể
    elitism_size=20,  # Tăng kích thước elitism
    mating_rate=0.8,  # Tăng tỉ lệ phối giống
    crossover_rate=0.9,  # Tăng tỉ lệ lai ghép
    base_mutation_rate=0.2,  # Sử dụng tỉ lệ đột biến thích nghi
    restart_threshold=50  # Sử dụng chiến lược khởi tạo lại định kỳ
)
tracking_result = tracking_chromosome_fitness(best_chromosome)
print(tracking_result)
lab_error_cases = {key: value for key, value in tracking_result['error_cases'].items() if 'lab' in key}

# In ra các lỗi liên quan đến lab
for key, value in lab_error_cases.items():
    print(f"{key}: {value}")
import numpy as np
import random
from collections import defaultdict
from tqdm import tqdm
import matplotlib.pyplot as plt


def plot_fitness(global_logging):
    generations = [log['generation'] for log in global_logging]
    best_fitness = [log['best_fitness'] for log in global_logging]

    plt.figure(figsize=(10, 6))
    plt.plot(generations, best_fitness, marker='o', linestyle='-', color='b')
    plt.xlabel('Generation')
    plt.ylabel('Best Fitness')
    plt.title('Fitness Progression Over Generations')
    plt.grid(True)
    plt.show()


# Call the function with global_logging data
plot_fitness(global_logging)

"""# Result Tracking

## Plot GA Fitness and Constraints
"""

# import matplotlib.pyplot as plt

# # Extract features from global_logging
# features = list(tracking_result['error_cases'].keys())

# # Iterate over each feature
# for feature in features:
#     # Create a new figure for each feature
#     plt.figure()

#     # Extract data for the current feature
#     data = [entry[feature] for entry in global_logging]

#     # Plot the line chart with dots at each index
#     plt.plot(range(len(data)), data)

#     # Add labels and title
#     plt.xlabel('Epoch')
#     plt.ylabel(feature)
#     plt.title(f'Line Chart for {feature}')
#     # Save the figure
#     plt.savefig(f'{feature}.png', format='png')
# # Show all the plots
# plt.show()

"""## Save as "Phản hồi"
"""


def generate_room_assignment(subject_id, room_dict):
    possible_rooms = [room for room, subjects in room_dict.items() if subject_id in subjects]
    if not possible_rooms:
        print(f"No possible rooms found for subject_id: {subject_id}")
    assigned_rooms = random.sample(possible_rooms, min(len(possible_rooms), len(subject_id)))
    return assigned_rooms

def update_room_assignment(df, start_index=0):
    room_assignments_cc_cn = defaultdict(list)
    room_assignments_l = defaultdict(list)

    # Tạo danh sách phòng học cho CC, CN và L
    for subject_id in df['Mã môn học'].unique():
        room_assignments_cc_cn[subject_id] = generate_room_assignment(subject_id, lab_room_cc_cn)
        room_assignments_l[subject_id] = generate_room_assignment(subject_id, lab_room_l)

    room_index = defaultdict(int)
    for index, row in df.iloc[start_index:].iterrows():
        subject_id = row['Mã môn học']
        group_id = row['Mã nhóm']
        if group_id.startswith('CC') or group_id.startswith('CN'):
            assigned_rooms = room_assignments_cc_cn[subject_id]
        elif group_id.startswith('L'):
            assigned_rooms = room_assignments_l[subject_id]
        else:
            assigned_rooms = []

        room_count = len(assigned_rooms)
        if room_count == 0:
            print(f"No rooms assigned for subject_id: {subject_id}, group_id: {group_id}")
            df.at[index, 'Mã Phòng'] = None
        else:
            df.at[index, 'Mã Phòng'] = assigned_rooms[room_index[subject_id] % room_count]
            room_index[subject_id] += 1

    return df

# Assuming data is a list of dictionaries where each dictionary represents a row of data
# Example:
data = []
for gen in merge_with_fixed_chromosome_and231(best_chromosome).chromosome:
    info = parse_gen(gen)
    new_row = {
        'Mã môn học': info.subject_id,
        'Tên môn học': SUBJECT_ID_TO_NAME.get(info.subject_id, "INVALID"),
        'Loại hình lớp': PROGRAM_ID_REVERSE.get(GROUP_ID_TO_PROGRAM_ID.get(info.group_id[:-2], "INVALID"), "INVALID"),
        'Mã nhóm': info.group_id,
        'Số tiết': NUMBER_OF_SESSION.get(info.subject_id, "INVALID"),
        'Mã GV': None,
        'Mã Phòng': None,
        'Loại Phòng': ROOM_TYPE_ID_REVERSE.get(info.room_type_id, "INVALID"),
        'Thứ': info.day,
        'Tiết BD': info.session_start,
    }
    for idx, bit in enumerate(info.weeks_bitstring):
        new_row[f"Week {idx + 1}"] = 'x' if bit == '1' else None
    data.append(new_row)

# Create a DataFrame from the data
df = pd.DataFrame(data)

# Update room assignment from row 211 onwards
start_index = 211
df = update_room_assignment(df, start_index)

k = len(fixed_chromosome.chromosome)
df = df.style.apply(lambda x: ['background: lightblue' if i < k else '' for i in range(len(x))])
# Define the file path to save the Excel file
file_path = '/Users/twang/Documents/GitHub/Sched/BK-Calendar-Ver2.5.xlsx'

# Write the DataFrame to an Excel file
df.to_excel(file_path, index=False)

print("Excel file saved successfully.")
#
# # !cp /content/{file_path} /gdrive/MyDrive/HCMUT-Scheduling/
#
# """## Save as "Tham khảo HK231"
# """

# import pandas as pd
#
# # Assuming data is a list of dictionaries where each dictionary represents a row of data
# # Example:
# data = []
# for gen in best_chromosome.chromosome:
#     info = parse_gen(gen)
#     new_row = {
#         'f_malp': "",
#         'f_mamh': info.subject_id,
#         'f_tenmhvn': SUBJECT_ID_TO_NAME.get(info.subject_id, "INVALID"),
#         'f_dvht': SUBJECT_INFO[info.subject_id]['f_dvht'],
#         'f_ts': SUBJECT_INFO[info.subject_id]['f_ts'],
#         'f_lt': SUBJECT_INFO[info.subject_id]['f_lt'],
#         'f_bt': SUBJECT_INFO[info.subject_id]['f_bt'],
#         'f_tn': SUBJECT_INFO[info.subject_id]['f_tn'],
#         'f_btl': SUBJECT_INFO[info.subject_id]['f_btl'],
#         'f_da': SUBJECT_INFO[info.subject_id]['f_da'],
#         'f_la': SUBJECT_INFO[info.subject_id]['f_la'],
#         'f_mh_mabm': None,
#         'f_mh_tenbm': PROGRAM_ID_REVERSE.get(GROUP_ID_TO_PROGRAM_ID.get(info.group_id[:-2], "INVALID"), "INVALID"),
#         'f_manh': info.group_id,
#         'f_sosv': None,
#         'f_sstb': 0,
#         'f_succhua': ROOM_TYPE_ID_REVERSE.get(info.room_type_id, "INVALID"),
#         'f_sosv1': None,
#         'f_sodk': None,
#         'f_tuan1': 0,
#         'f_thu': {i: calendar.day_name[i] for i in range(7)}.get(info.day - 2, "INVALID"),
#         'f_tietbd': info.session_start if NUMBER_OF_SESSION.get(info.subject_id,
#                                                                 "INVALID") != "INVALID" and NUMBER_OF_SESSION.get(
#             info.subject_id, "INVALID") + info.session_start in VALID_SESSION else "INVALID",
#         'f_sotiet': NUMBER_OF_SESSION.get(info.subject_id, "INVALID"),
#         'f_manv': None,
#         'f_holotvn': None,
#         'f_tenvn': None,
#         'f_mabm': None,
#         'f_tenbm': None,
#         'f_tenph': None,
#         'f_diadiem': FACILITY_ID[FACILITY[info.group_id[:-2]]],
#         'f_mamh_lt': None,
#         'f_makhoa': 'MT',
#         'f_tenkhoa': 'KH & KT Máy tính',
#         'f_manh_lt': None
#     }
#     for idx, bit in enumerate(info.weeks_bitstring):
#         new_row[f"t{idx + 1}"] = 'x' if bit == '1' else None
#     data.append(new_row)
#
# # Create a DataFrame from the data
# df = pd.DataFrame(data)
#
# # Define the file path to save the Excel file
# file_path = '/Users/vinhvu/Sched/TKB-241.xlsx'
#
# # Write the DataFrame to an Excel file
# df.to_excel(file_path, index=False)
#
# print("Excel file saved successfully.")
#
# """# Appendix: Hyper parameters Number of room in each facility
#
# ```
# # Param 1
# NUMBER_OF_ROOM = { # '-'.join(facility, room_type_id) BK-DAn, BK-LTK
#     "DAn-1": 30, # loại phòng 40 chỗ
#     "DAn-2": 5, # loại phòng 60 chỗ
#     "DAn-3": 20, # loại phòng 80 chỗ
#     "DAn-4": 5, # loại phòng 140 chỗ
#     "DAn-5": 3, # loại phòng 160 chỗ
#     "DAn-6": 2, # loại phòng 200 chỗ (hội trường, 211H1)
#
#     "LTK-1": 30,
#     "LTK-2": 5,
#     "LTK-3": 20,
#     "LTK-4": 5,
#     "LTK-5": 3,
#     "LTK-6": 2
# }
# # Param 2
# NUMBER_OF_ROOM = { # '-'.join(facility, room_type_id) BK-DAn, BK-LTK
#     "DAn-1": 30, # loại phòng 40 chỗ
#     "DAn-2": 5, # loại phòng 60 chỗ
#     "DAn-3": 10, # loại phòng 80 chỗ
#     "DAn-4": 5, # loại phòng 140 chỗ
#     "DAn-5": 3, # loại phòng 160 chỗ
#     "DAn-6": 2, # loại phòng 200 chỗ (hội trường, 211H1)
#
#     "LTK-1": 30,
#     "LTK-2": 5,
#     "LTK-3": 10,
#     "LTK-4": 5,
#     "LTK-5": 3,
#     "LTK-6": 2
# }
# ```
#
#
#
# ```
# tracking_log dict_items([('total_invalid_cases', 0), ('invalid_day', 0), ('invalid_session_start', 0), ('invalid_room_type_id', 0), ('smaller_room', 0), ('overload_room_cases', 0)])
#
# ```
#
# ```
# NUMBER_OF_ROOM = { # '-'.join(facility, room_type_id) BK-DAn, BK-LTK
#     "DAn-1": 25, # loại phòng 40 chỗ
#     "DAn-2": 10, # loại phòng 60 chỗ
#     "DAn-3": 15, # loại phòng 80 chỗ
#     "DAn-4": 5, # loại phòng 140 chỗ
#     "DAn-5": 5, # loại phòng 160 chỗ
#     "DAn-6": 5, # loại phòng 200 chỗ (hội trường, 211H1)
#
#     "LTK-1": 25,
#     "LTK-2": 10,
#     "LTK-3": 15,
#     "LTK-4": 5,
#     "LTK-5": 5,
#     "LTK-6": 5
# }
# ```
#
#
#
# ```
# tracking_log dict_items([('total_invalid_cases', 6), ('invalid_day', 1), ('invalid_session_start', 3), ('invalid_room_type_id', 2), ('smaller_room', 1), ('overload_room_cases', 0)])
# ```
#
# ```
# NUMBER_OF_ROOM = { # '-'.join(facility, room_type_id) BK-DAn, BK-LTK
#     "DAn-1": 25, # loại phòng 40 chỗ
#     "DAn-2": 10, # loại phòng 60 chỗ
#     "DAn-3": 10, # loại phòng 80 chỗ
#     "DAn-4": 5, # loại phòng 140 chỗ
#     "DAn-5": 5, # loại phòng 160 chỗ
#     "DAn-6": 5, # loại phòng 200 chỗ (hội trường, 211H1)
#
#     "LTK-1": 25,
#     "LTK-2": 10,
#     "LTK-3": 10,
#     "LTK-4": 5,
#     "LTK-5": 5,
#     "LTK-6": 5
# }
# ```
#
#
#
# ```
# tracking_log dict_items([('total_invalid_cases', 4), ('invalid_day', 1), ('invalid_session_start', 3), ('invalid_room_type_id', 0), ('smaller_room', 1), ('overload_room_cases', 1)])
#
#
# ```
#
# ```
# NUMBER_OF_ROOM = { # '-'.join(facility, room_type_id) BK-DAn, BK-LTK
#     "DAn-1": 20, # loại phòng 40 chỗ
#     "DAn-2": 15, # loại phòng 60 chỗ
#     "DAn-3": 10, # loại phòng 80 chỗ
#     "DAn-4": 5, # loại phòng 140 chỗ
#     "DAn-5": 5, # loại phòng 160 chỗ
#     "DAn-6": 5, # loại phòng 200 chỗ (hội trường, 211H1)
#
#     "LTK-1": 20,
#     "LTK-2": 15,
#     "LTK-3": 10,
#     "LTK-4": 5,
#     "LTK-5": 5,
#     "LTK-6": 5
# }
# ```
#
#
#
# ```
# tracking_log dict_items([('total_invalid_cases', 44), ('invalid_day', 10), ('invalid_session_start', 18), ('invalid_room_type_id', 17), ('smaller_room', 4), ('overload_room_cases', 3)])
#
# ```
#
# # Appendix: Visualize helper function
# """
#
#
# def visualize_calendar(chromosome):
#     time_loc_dict = {}
#     global_active = []
#     keys_index = ['week', 'day', 'session_start', 'num_session', 'facility', 'room_type_id']
#     for gen in chromosome.chromosome:
#         info = parse_gen(gen)
#
#         facility = FACILITY[info.group_id[
#                             :-2]]  # get value of key (L or CC or CN) because the 2 last letter is number of group liek 01, 02
#         for idx, bit in enumerate(info.weeks_bitstring):
#             if bit == '1':
#                 _key = {
#                     "week": idx + 1,
#                     "day": info.day,
#                     "session_start": info.session_start,
#                     "num_session": NUMBER_OF_SESSION[info.subject_id],
#                     "facility": facility,
#                     "room_type_id": info.room_type_id
#                 }
#                 _key = tuple(list(_key.values()))
#                 if _key in time_loc_dict:
#                     time_loc_dict[_key] += [(info.subject_id, info.group_id)]
#                 else:
#                     time_loc_dict[_key] = [(info.subject_id, info.group_id)]
#
#                 global_active.append(_key)
#
#     sort_keys = ['week', 'facility', 'day', 'session_start', 'room_type_id']
#     sort_keys = [keys_index.index(key) for key in sort_keys]
#     sorted_global_active = sorted(global_active, key=lambda x: tuple(x[i] for i in sort_keys))
#
#     def add_key_name(key):
#         week, day, session_start, num_session, facility, room_type_id = key
#         day = {i: calendar.day_name[i] for i in range(7)}.get(day - 2)
#         key = f"Week {week}|Facility BK-{facility}|{day}|Session {session_start}-{session_start + num_session}|Room Type {room_type_id}"
#         return key
#
#     result = {add_key_name(key): time_loc_dict[key] for key in sorted_global_active}
#     return result
#
#
# visualize_calendar(population[0])
#
# import json
#
# with open("BK-Calendar.json", 'w') as json_file:
#     json.dump(visualize_calendar(population[0]), json_file, indent=4)