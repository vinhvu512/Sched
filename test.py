# -*- coding: utf-8 -*-
"""Copy of HCMUT-SCHEDULING-Sol-2 (refactored + docs).ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1Jfz8pd3yo2aMwkaYyR7IoBUekhKnIUsu

<!DOCTYPE html>
<html>
<head>
    <style>
        table {
            width: 50%;
            border-collapse: collapse;
            margin: 20px auto;
        }
        th, td {
            border: 1px solid #dddddd;
            text-align: left;
            padding: 15px;
        }
        th {
            background-color: #f2f2f2;
        }
    </style>
</head>
<body>
<center>
<img src="https://hcmut.edu.vn/img/nhanDienThuongHieu/bk_name_en.png" alt="hcmut logo"/>

<table>
    <tr>
        <th>Role</th>
        <th>Name</th>
        <th>ID</th>
    </tr>
    <tr>
        <td>Institution</td>
        <td>Ho Chi Minh University of Technology</td>
        <td></td>
    </tr>
    <tr>
        <td>Instructor</td>
        <td>Quan Thanh Tho</td>
    </tr>
    <tr>
        <td></td>
        <td>Nguyen Minh Tam</td>
    </tr>
    <tr>
        <td>Members</td>
        <td>Cao Tri</td>
        <td>2010733</td>
    </tr>
    <tr>
        <td></td>
        <td>Vu Vinh</td>
        <td></td>
    </tr>
    <tr>
        <td></td>
        <td>Pham Quang</td>
        <td></td>
    </tr>
</table>

</center>
</body>
</html>

# Introduction
Mục tiêu là sắp xếp các lớp học vào thời khóa biểu. Vì sao lại là lớp học, vì lớp học là 1 chủ thể unique, từ đây có thể định ra được teacher và các student tham gia

Xem thêm tại `brainstorm.docs` trong cùng thư mục
"""

# from google.colab import drive
# drive.mount('/gdrive', force_remount=True)
#
# !ls /gdrive/MyDrive/HCMUT-Scheduling/
#
# !cp /gdrive/MyDrive/HCMUT-Scheduling/Dự-kiến-SVMT_241.xlsx /content/
# !cp /gdrive/MyDrive/HCMUT-Scheduling/"Dự kiến SVMT_241 (thầy Cường).xlsx" /content/
# !cp /gdrive/MyDrive/HCMUT-Scheduling/"final_TKB_update20230915.xlsx" /content/

import os

from holoviews.ipython import display
from tqdm import tqdm
import numpy as np
import pandas as pd
import random
from copy import deepcopy
from collections import namedtuple
from typing import Union, List
import calendar
import math
import pandas as pd
from collections import defaultdict
from itertools import combinations
import gdown

# url_dk241 = "https://docs.google.com/spreadsheets/d/1hV1XwhXpQaPgd0mTZ8_xmxIyRPpVEXyQ/edit?usp=drive_link&ouid=105374451612561775917&rtpof=true&sd=true"
# sheet_dk241 = "Dự-kiến-SVMT_241.xlsx"
# url_dk241_thaycuong = "https://docs.google.com/spreadsheets/d/1WQFBxemnXNcpHL9bGma3TTBcw50y9x24/edit?usp=drive_link&ouid=105374451612561775917&rtpof=true&sd=true"
# sheet_dk241_thaycuong = "Dự kiến SVMT_241 (thầy Cường).xlsx"
# url_tkb231 = "https://docs.google.com/spreadsheets/d/1QyUzXdfXU0os2TeVQ5qtCrUj6SqvRtiJ/edit?usp=drive_link&ouid=105374451612561775917&rtpof=true&sd=true"
# sheet_tkb231 = "final_TKB_update20230915.xlsx"
# gdown.download(url_dk241, sheet_dk241, quiet=False)
# gdown.download(url_dk241_thaycuong, sheet_dk241_thaycuong, quiet=False)
# gdown.download(url_tkb231, sheet_tkb231, quiet=False)

random.seed(42)  # cố định kết quả chạy vì có sử dụng random

SHEET_FILE_NAME = "Dự-kiến-SVMT_241.xlsx"
FIXED_SHEET_FILE_NAME = ["Dự kiến SVMT_241 (thầy Cường).xlsx"]  # sau này nếu có thêm file đề xuất thì append vào
REFERENCE_SHEET_FILE_NAME = "final_TKB_update20230915.xlsx"  # file tham khảo từ 1 học kỳ trước. Ở đây là 231
LAB_SHEET_FILE_NAME = "HK241_CSE_Xep TKB ThucHanh-ThiNghiem.xlsx"
LAB_SHEET_NAMES = ['HK241 TKB LAB', 'CS1', 'CS2']
SHEET_FILE_PATH = f"/Users/vinhvu/Sched/{SHEET_FILE_NAME}"
SHEET_NAMES = ['Thống kê', 'Phản hồi', 'KHGD', 'Môn học', 'reference']  # 'reference' đại diện cho file HK231

assert os.path.exists(SHEET_FILE_PATH)
assert all(os.path.exists(fixed_sheet_file) for fixed_sheet_file in FIXED_SHEET_FILE_NAME)
assert os.path.exists(REFERENCE_SHEET_FILE_NAME)

data0 = pd.read_excel(SHEET_FILE_PATH, sheet_name=SHEET_NAMES[0])
data0

data1 = pd.read_excel(SHEET_FILE_PATH, sheet_name=SHEET_NAMES[1])
data1

data2 = pd.read_excel(SHEET_FILE_PATH, sheet_name=SHEET_NAMES[2])
data2

data3 = pd.read_excel(SHEET_FILE_PATH, sheet_name=SHEET_NAMES[3])
data3

data4 = pd.read_excel(FIXED_SHEET_FILE_NAME[0], sheet_name=SHEET_NAMES[1])
data4

data0 = data0.dropna(subset=['Số lượng nhóm'])
data0.info()

data0.groupby(['Sỉ số SV max', 'Loại hình lớp'])['Số lượng nhóm'].sum()

"""**Từ quan sát, nhận thấy, file tham khảo (HK231) khi được fixed vào sau cùng sau khi đã thông qua đề xuất của các thầy, thì file tham khảo nào cũng như 1 file đề xuất của 1 thầy ẩn danh. Do đó, mục tiêu là chuyển đổi format hiện tại của file tham khảo về như 1 file đề xuất (của các thầy).**"""

ref_data = pd.read_excel(REFERENCE_SHEET_FILE_NAME)
# Lọc của khoa máy tính & không phải thí nghiệm
ref_data = ref_data[(ref_data['f_makhoa'] == 'MT')]
ref_data


# Một số môn ở học kỳ này bị split thời khoa biểu, do đó cần merge lại
def overlap_splited_rows(ref_data):
    # Group by the columns that define duplicates
    grouped = ref_data.groupby(['f_mamh', 'f_manh'])

    # Define an aggregation function that returns the first non-null value
    def first_non_null(series):
        return series.dropna().iloc[0] if not series.dropna().empty else None

    # Apply the aggregation function to each group
    return grouped.agg(first_non_null).reset_index()


ref_data = overlap_splited_rows(ref_data)

"""## Mapped Variables"""

# ROOM_ID = ["CQ", "CC", "CN"]

FACULTY_ID = {
    "Khoa học máy tính": "CS",
    "Kỹ thuật máy tính": "CE"
}

PROGRAM_ID = {
    "Chương trình giảng  dạy bằng tiếng Anh": "CC",
    "Chương trình giảng dạy bằng tiếng Anh": "CC",
    "Chương trình tiêu chuẩn": "CQ",
    "Chương trình định hướng Nhật Bản": "CN",
    "Cử nhân tài năng": "TN"
}
PROGRAM_ID_REVERSE = {value: key for key, value in PROGRAM_ID.items()}

ROOM_TYPE_ID = {
    30.0: "1",
    39.9: "2",
    40.0: "3",
    60.0: "4",
    80.0: "5",
    140.0: "6",
    160.0: "7",
    200.0: "8",
}

ROOM_TYPE_ID_REVERSE = {val: key for key, val in ROOM_TYPE_ID.items()}

# Lưu ý: đây là trường hợp cho kết quả tốt nhất (có lẽ vì phân phối của phòng tương đương với ```data0['Sỉ số SV max'].value_counts()``` bên trên)
# Với số phòng nhỏ hơn, GA ko hội tụ. Do đó cần cung cấp số liệu chính xác hoặc GA cải tiến đa mục tiêu
# Kết quả đo đạc dưới phần Appendix
NUMBER_OF_ROOM = {  # '-'.join(facility, room_type_id) BK-DAn, BK-LTK
    "DAn-1": 4,  # loại phòng 30 chỗ
    "DAn-2": 5,  # loại phòng 400 chỗ (hội trường, 211H1)
    "DAn-3": 28,  # loại phòng 40 chỗ
    "DAn-4": 15,  # loại phòng 60 chỗ
    "DAn-5": 15,  # loại phòng 80 chỗ
    "DAn-6": 15,  # loại phòng 140 chỗ
    "DAn-7": 15,  # loại phòng 160 chỗ
    "DAn-8": 10,  # loại phòng 200 chỗ (hội trường, 211H1)

    "LTK-1": 1,
    "LTK-2": 4,
    "LTK-3": 25,
    "LTK-4": 15,
    "LTK-5": 15,
    "LTK-6": 15,
    "LTK-7": 15,
    "LTK-8": 10,
}


FACILITY_ID = {
    "LTK": 1,
    "DAn": 2
}

FACILITY = {
    "L": "DAn",
    "CC": "LTK",
    "CN": "LTK",
    "TN": "DAn"
}

MAX_ACTIVE_WEEKS = 18  # max number of weeks which is active

PROGRAM_ID_TO_GROUP_ID = {
    "CQ": "L",
    "CC": "CC",
    "CN": "CN",
    "TN": "TN"
}

GROUP_ID_TO_PROGRAM_ID = {val: key for key, val in PROGRAM_ID_TO_GROUP_ID.items()}

VALID_DAY = range(2, 7)  # active day of university, except Saturday and Sunday
VALID_SESSION_START = range(2, 12)  # active session start, 11 mean 16h, I think the shortest class must be in 2 hours
VALID_ROOM_TYPE_ID = [str(r) for r in range(1, 9)]
VALID_SESSION = range(2, 14)

VI_TO_EN_COLUMN_NAMES = {
    'Mã môn học': 'subject_id',
    'Loại hình lớp': 'program',
    'Số lượng nhóm': 'num_of_group',
    'Sỉ số SV max': 'room_cap_id',
    'Mã nhóm': 'group_id',
    'Số tiết': 'num_session',
    'Số tuần học': 'num_of_learning_week',
    'Tuần kiểm tra giữa kỳ': 'midterm_week',
    'Học kỳ chính': 'main_term',
    'Tên ngành': 'faculty',
    'Thứ': 'day',
    "Thứ ": 'day',
    'Tiết BD': 'session_start',
    ######
    'f_mamh': 'subject_id',
    'f_manh': 'group_id',
    'f_sotiet': 'num_session',
    'f_manv': 'teacher_id',
    'f_thu': 'day',
    'f_tietbd': 'session_start',
}

MIDTERM_ALL = 8

"""## Preprocess Sheet File"""


# Đây là hàm thống nhất để preprocess tất cả sheet file
def preprocess_raw_data(df, sheet_name):
    # Rename column's name from vi2en
    replace_columns = {key: val for key, val in VI_TO_EN_COLUMN_NAMES.items() if key in df.columns}
    df = df.rename(columns=replace_columns, inplace=False)

    # Select processor by sheet name
    assert sheet_name in SHEET_NAMES + ['reference'], "Đây không phải là sheet hợp lệ"

    if sheet_name == SHEET_NAMES[0]:
        # Select columns
        df = df[['subject_id', 'program', 'num_of_group', 'room_cap_id']]
        # Drop NaN rows (missing num of class)
        df = df.dropna()
        # Mapping
        df['program'] = df['program'].map(PROGRAM_ID)
        df['room_cap_id'] = df['room_cap_id'].map(ROOM_TYPE_ID)
        df['num_of_group'] = df['num_of_group'].astype(int)

    elif sheet_name == SHEET_NAMES[1]:
        # df = df[df['num_session']]  # loại bỏ tiết thí nghiệm
        df['program'] = df['program'].map(PROGRAM_ID)
        df['day'] = df['day'].astype(int)
        df['session_start'] = df['session_start'].astype(int)

    elif sheet_name == SHEET_NAMES[3]:
        # Select columns
        select_columns = ['subject_id', 'num_session', 'num_of_learning_week', 'midterm_week', 'main_term', 'faculty']
        df = df[select_columns]
        # Drop NaN rows (missing num of class)
        # df = df[df['num_session'] != 0]
    elif sheet_name == 'reference':
        list_weeks = [t for t in df.columns if t[0] == 't' and t[1:].isdigit() and int(t[1:]) <= 18]
        select_columns = ['subject_id', 'group_id', 'num_session', 'teacher_id', 'day', 'session_start']
        select_columns += list_weeks
        df = df[select_columns]
        df = df.rename(columns={t: t.upper() for t in list_weeks}, inplace=False)
        # Loại bỏ các lớp dự thính DT, các lớp CT và các lớp T gì đó
        df = df[[x[:-2] in GROUP_ID_TO_PROGRAM_ID.keys() for x in df['group_id']]]
        df['program'] = df['group_id'].apply(lambda x: GROUP_ID_TO_PROGRAM_ID.get(x[:-2]))
        df = df[(df['day'] != 0) & (df['session_start'] != 0)]
    return df


ref_df = preprocess_raw_data(ref_data, "reference")
ref_df

df0 = preprocess_raw_data(data0, SHEET_NAMES[0])
df0

df0.num_of_group.sum()

df3 = preprocess_raw_data(data3, SHEET_NAMES[3])
df3

df0.merge(df3, on='subject_id').groupby(['num_session'])['num_of_group'].sum()

df4 = preprocess_raw_data(data4, SHEET_NAMES[1])
df4

"""## Cache Variables"""

############# Untils function ##################
MIN_CAP_ROOM_TYPE_ID = {
    f"{subject_id}-{program}": int(room_cap_id)
    for subject_id, program, room_cap_id in df0[['subject_id', 'program', 'room_cap_id']].itertuples(index=False)
}

NUMBER_OF_SESSION = {
    subject_id: num_session
    for subject_id, num_session in df3[['subject_id', 'num_session']].itertuples(index=False)
}

SUBJECT_ID_TO_NAME = {
    subject_id: subject_name.strip()
    for subject_id, subject_name in data0[['Mã môn học', 'Tên môn học']].itertuples(index=False)
}

SUBJECT_TERM = {
    subject_id: {
        "main_term": main_term,
        "midterm_week": midterm_week
    }
    for subject_id, main_term, midterm_week in df3[['subject_id', 'main_term', 'midterm_week']].itertuples(index=False)
}

SUBJECT_IN_FALCUTY = {
    subject_id: faculty
    for subject_id, faculty in df3[['subject_id', 'faculty']].itertuples(index=False)
}

SUBJECT_INFO = {
    subject_id: {
        "f_dvht": f_dvht,
        "f_ts": f_ts,
        "f_lt": f_lt,
        "f_bt": f_bt,
        'f_tn': f_tn,
        'f_btl': f_btl,
        'f_da': f_da,
        'f_la': f_la,
    }
    for subject_id, f_dvht, f_ts, f_lt, f_bt, f_tn, f_btl, f_da, f_la
    in data2[['Mã MH', 'Tín chỉ', 'Tổng tiết', 'Lý thuyết', 'Bài tập', 'Thí nghiệm', 'BTL', 'DA', 'LA']].itertuples(
        index=False)
}


def get_min_cap_room_type_id(subject_id, group_id):
    program = GROUP_ID_TO_PROGRAM_ID[group_id[:-2]]
    return MIN_CAP_ROOM_TYPE_ID.get(f"{subject_id}-{program}", 1)


TEACHER_IN_SUBJECT_ID = {
    f"{subject_id}-{group_id}": teacher_id
    for subject_id, group_id, teacher_id
    in ref_df[['subject_id', 'group_id', 'teacher_id']].itertuples(index=False)
}

"""# Class GA"""


class CHROMOSOME_GA_BASE:
    pass


GenStruct = namedtuple(
    "GenStruct",
    [
        "subject_id",
        "group_id",
        "day",
        "session_start",
        "room_type_id",
        "weeks_bitstring",
    ], defaults=[None] * 6
)


def parse_gen(gen):
    info_list = gen.split('-')

    # unique tuple attributes
    subject_id = info_list[0]
    group_id = info_list[1]

    # predict attribute
    bitstring = info_list[2]
    day = int(bitstring[0: 3], 2)
    session_start = int(bitstring[3: 7], 2)
    room_type_id = str(int(bitstring[7: 10], 2))
    weeks_bitstring = bitstring[10:]

    return GenStruct(subject_id, group_id, day, session_start, room_type_id, weeks_bitstring)


"""## Chromosome GA Fixed

Hàm `add` là 1 **hàm quan trọng**. Khi khởi tạo `__init__` 1 fixed chromosome từ 1 file đề xuất. Các file đề xuất tiếp theo chỉ cần `add` vào lần lượt theo thứ tự. *Lưu ý: cần bổ sung thêm file dự kiến để cập nhật lại các lớp không cần phải thêm nữa. Hàm sẽ trả về file dự kiến mới với các lớp còn lại cần phải nhờ GA.* Ví dụ:  
Giả sử df4 là file để xuất từ thầy Cường, df5 là file đề xuất từ thầy Dũng (ưu tiên thấp hơn), df0 là file dự kiến và ref_df là file tham khảo từ học kỳ trước.
```
fixed_chromosome = CHROMOSOME_GA_FIXED(df4)
remain_df0 = fixed_chromosome.add(df5, df0)
remain_df0 = fixed_chromosome.add(ref_df, remain_df0)
```
"""


class CHROMOSOME_GA_FIXED(CHROMOSOME_GA_BASE):
    def __init__(self, df0):
        assert all(colname in df0.columns for colname in
                   ['subject_id', 'program', 'group_id', 'num_session', 'day', 'session_start'])
        self.df0 = df0
        self.fixed_classes = []
        self.chromosome = self._generate_parent(df0)

    # Generate random date
    def _generate_parent(self, _df):
        chromosome = []
        for subject_id, program, group_id, num_session, day, session_start in zip(
                _df.subject_id,
                _df.program,
                _df.group_id,
                _df.num_session,
                _df.day,
                _df.session_start,
        ):
            program2 = PROGRAM_ID_TO_GROUP_ID.get(program, "L")
            day = format(day, "03b")
            session_start = format(session_start, "04b")
            room_type_id = format(MIN_CAP_ROOM_TYPE_ID.get(f"{subject_id}-{program}", 1), "03b")  # hiện tại chưa có
            weeks_bitstring = self.get_weeks_bitstring(subject_id, group_id, _df)
            ################# For testing
            if '1' not in weeks_bitstring:
                continue
            #################
            bitstring = "".join([day, session_start, room_type_id, weeks_bitstring])
            # Combine to genes
            genes = "-".join([subject_id, group_id, bitstring])
            chromosome.append(genes)
            self.fixed_classes.append(f"{subject_id}-{group_id}")
        return np.asarray(chromosome)

    def get_weeks_bitstring(self, subject_id, group_id, _df):
        # Filter the DataFrame based on subject_id and group_id
        filtered_df = _df[(_df['subject_id'] == subject_id) & (_df['group_id'] == group_id)]
        # Count the number of 'x' values in T columns
        # x_count = filtered_df.filter(like='T').sum().astype(int)
        list_bits = filtered_df.filter(like='T').eq('x').sum().astype(str).to_list()
        return "".join(list_bits)

    def add(self, _ref_df, _new_df):
        assert all(colname in _ref_df.columns for colname in ['subject_id', 'program', 'group_id', 'num_session', 'day',
                                                              'session_start']), "DataFrame does not contain valid columns"
        assert all(colname in _new_df.columns for colname in
                   ['subject_id', 'program', 'num_of_group']), "DataFrame does not contain valid columns"

        for subject_id, program in _new_df[['subject_id', 'program']].itertuples(index=False):
            # Trong các môn của học kỳ mới, môn nào có một số lớp của học kỳ cũ thì bổ sung vào trước
            sub_new_df = _new_df[(_new_df['subject_id'] == subject_id) & (_new_df['program'] == program)]
            num_of_new_group = sub_new_df['num_of_group'].values[0]

            # Một số lớp đã có trong fixed trước đó rồi
            already_group_exists = self.get_group_ids_by_subject_id(subject_id)
            already_group_exists = [x for x in already_group_exists if x.startswith(PROGRAM_ID_TO_GROUP_ID[program])]

            # Cập nhật lại số lượng lớp cần xử lý
            num_of_new_group -= len(already_group_exists)

            if num_of_new_group > 0:

                ref_df = _ref_df[(_ref_df['subject_id'] == subject_id) & (_ref_df['program'] == program)]

                if num_of_new_group == len(ref_df):  # vừa đủ
                    new_chromosome = self._generate_parent(ref_df)
                    # ???????????????? Cần xét thêm điều kiện mới concatenate
                    self.chromosome = np.concatenate([self.chromosome, new_chromosome])
                    num_of_new_group = 0
                elif num_of_new_group > len(
                        ref_df):  # các lớp ở học kỳ cũ của chương trình này là không đủ lớp với so với học kỳ mới
                    new_chromosome = self._generate_parent(ref_df)
                    self.chromosome = np.concatenate([self.chromosome, new_chromosome])
                    num_of_new_group -= len(ref_df)
                elif num_of_new_group < len(
                        ref_df):  # các lớp ở học kỳ cũ của chương trình này là nhiều hơn lớp với so với học kỳ mới
                    new_chromosome = self._generate_parent(ref_df.sort_values(by='group_id').head(num_of_new_group))
                    self.chromosome = np.concatenate([self.chromosome, new_chromosome])
                    num_of_new_group = 0

            # Cập nhật lại số lớp cần chạy GA phía dưới
            _new_df.loc[sub_new_df.index, 'num_of_group'] = num_of_new_group

        remain_df = _new_df
        return remain_df

    # Mục tiêu của hàm này là lấy danh sách các mã lớp đã có của 1 môn học
    def get_group_ids_by_subject_id(self, subject_id):
        selected_gen = [gen for gen in self.chromosome if gen.startswith(subject_id)]
        return [gen.split('-')[1] for gen in selected_gen]


# Hiển thị file dự kiến ban đâu
display(df0)
# Sau khi fix 1 file đề xuất đầu tiên
fixed_chromosome = CHROMOSOME_GA_FIXED(df4)
display(fixed_chromosome.chromosome)
print(len(fixed_chromosome.chromosome))
# Tiếp tục là 1 file đề xuất khác (ở đây là chính file tham khảo)
remain_df0 = fixed_chromosome.add(ref_df, df0)
# Số lớp của file dự kiến được cập nhật
display(remain_df0)
display(fixed_chromosome.chromosome)
print(len(fixed_chromosome.chromosome))

"""## Chromosome GA"""


class CHROMOSOME_GA(CHROMOSOME_GA_BASE):
    def __init__(self, df0, df1):
        assert all(colname in df0.columns for colname in ['subject_id', 'program', 'num_of_group', 'room_cap_id'])
        assert all(
            colname in df1.columns for colname in ['subject_id', 'num_of_learning_week', 'num_session', 'midterm_week'])
        self.df0 = df0
        self.df1 = df1
        self.chromosome = self._generate_parent()

    # Generate random date
    def _generate_parent(self):
        chromosome = []
        subject_id_same_week_bitstring = {}
        global fixed_chromosome
        for subject_id, program, num_of_group, room_cap_id in zip(
                self.df0.subject_id,
                self.df0.program,
                self.df0.num_of_group,
                self.df0.room_cap_id,
        ):
            program2 = PROGRAM_ID_TO_GROUP_ID.get(program, "L")
            # Một vài mã lớp đã tồn tại ở fixed chromosome rồi, cần đẩy index lên
            exists_group_ids = fixed_chromosome.get_group_ids_by_subject_id(subject_id)
            exists_group_ids = [x for x in exists_group_ids if x.startswith(program2)]
            start_id = len(
                exists_group_ids)  # !!!!! giả sử các lớp trước đã sort rồi nhé, ví dụ có 2 lớp thì phải là L01, L02 hoặc CC01, CC02
            group_ids = [f"{program2}{(i + 1):02d}" for i in
                         range(start_id, start_id + num_of_group)]  # L01, L02, CC01, CC02, CN01
            for group_id in group_ids:
                ############# Trong trường hợp các lớp đã fixed trước, bỏ qua ############
                if f"{subject_id}-{group_id}" in fixed_chromosome.fixed_classes:
                    continue
                #########################################################################################
                day = format(random.randint(VALID_DAY.start, VALID_DAY.stop - 1), "03b")
                session_start = format(random.randint(VALID_SESSION_START.start, VALID_SESSION_START.stop - 1), "04b")
                room_type_id = format(int(room_cap_id), "03b")
                weeks_require = self.get_num_of_weeks_require(subject_id)
                if weeks_require == 0:
                    continue

                weeks_bitstring = subject_id_same_week_bitstring.get(subject_id,
                                                                     self.random_weeks_bitstring(weeks_require,
                                                                                                 subject_id))
                subject_id_same_week_bitstring[subject_id] = weeks_bitstring
                ################# For testing
                if '1' not in weeks_bitstring:
                    continue
                #################
                bitstring = "".join([day, session_start, room_type_id, weeks_bitstring])
                # Combine to genes
                genes = "-".join([subject_id, group_id, bitstring])
                chromosome.append(genes)
        return np.asarray(chromosome)

    def random_weeks_bitstring(self, K, subject_id):
        if K == 0:
            return "0" * MAX_ACTIVE_WEEKS
        midterm = SUBJECT_TERM[subject_id]['midterm_week']
        if K >= 7:  # môn lý thuyết
            # học full 6 tuần đầu, nghỉ 1 trong 2 tuần 7 và 8, học các tuần còn lại
            k = round(K)
            return '1' * 6 + random.choice(["01", '10']) + '1' * (k - 7) + '0' * (MAX_ACTIVE_WEEKS - k - 1)
        else:  # môn thí nghiệm
            # TODO: tính toán sau, bên dưới chỉ đề đỡ
            # 6 bit đầu là 0, 12 bit sau sẽ là K số 1 random xen kẽ
            bitstring = '0' * 6
            remaining_bits = MAX_ACTIVE_WEEKS - 6
            ones_to_place = K

            bit_list = ['0'] * (remaining_bits)

            # Place ones randomly in the remaining 12 bits
            available_positions = list(range(remaining_bits))
            random.shuffle(available_positions)
            ones_positions = sorted(available_positions[:K])

            for pos in ones_positions:
                bit_list[pos] = '1'

            # Convert list back to string
            bitstring += ''.join(bit_list[:12])

            return bitstring

    def get_num_of_weeks_require(self, _subject_id):
        for subject_id, num_of_learning_week in self.df1[['subject_id', 'num_of_learning_week']].itertuples(
                index=False):
            if subject_id == _subject_id:
                return num_of_learning_week
        print(_subject_id)


chromosome = CHROMOSOME_GA(remain_df0, df3)
chromosome.chromosome

"""# Class Struct & Class Dict Global

Mục đích sau cùng của các utils function là hard dữ liệu. Vì vậy, với bộ dữ liệu thực tế, chúng ta thay đổi các tác vụ load data để sau cùng thống nhất về `ClassDictGlobal` để truy xuất trên RAM/Cache nhanh nhất
"""

ClassStruct = namedtuple(
    "ClassStruct",
    [
        "subject_id",
        "group_id",
        "subject_name",
        "min_capable_room_type_id",
        "num_of_session",
        "program",
        "teacher_id",
        "num_of_learning_week",
        "midterm_week",
        "facility",
        "faculty",
        "main_term"
    ], defaults=["", "", "", 1, 2, "CQ", "", 15, 0, "DAn", "CS", 3]
)

ClassDictGlobal = {}
for gen in np.concatenate((chromosome.chromosome, fixed_chromosome.chromosome)):
    info = parse_gen(gen)
    class_struct = {
        "subject_id": info.subject_id,
        "group_id": info.group_id,
        "subject_name": SUBJECT_ID_TO_NAME[info.subject_id],
        "min_capable_room_type_id": get_min_cap_room_type_id(info.subject_id, info.group_id),
        "num_of_session": NUMBER_OF_SESSION[info.subject_id],
        "program": GROUP_ID_TO_PROGRAM_ID[info.group_id[:-2]],
        "facility": FACILITY[PROGRAM_ID_TO_GROUP_ID[GROUP_ID_TO_PROGRAM_ID[info.group_id[:-2]]]],
        "faculty": SUBJECT_IN_FALCUTY.get(info.subject_id, "CS"),
        "main_term": SUBJECT_TERM.get(info.subject_id, {}).get("main_term", 3),
        "midterm_week": SUBJECT_TERM.get(info.subject_id, {}).get("midterm_week", 7),
        "teacher_id": TEACHER_IN_SUBJECT_ID.get(f"{info.subject_id}-{info.group_id}",
                                                f"{info.subject_id}_{random.randint(1, 4):02}")
    }
    ClassDictGlobal[f"{info.subject_id}-{info.group_id}"] = ClassStruct(**class_struct)

ClassDictGlobal

"""# GA Algorithm"""


############# GA Module ##################


def init_population(data0, data1, size_of_population):
    new_population = []
    for i in range(size_of_population):
        new_individual = CHROMOSOME_GA(data0, data1)
        new_population.append(new_individual)
    new_population = np.asarray(new_population)
    return new_population


def select_mating_pool(population, mating_rate, fitness_list):
    if fitness_list is None:
        fitness_list = [1] * len(population)
    assert len(population) == len(fitness_list)
    # Convert fitness list to numpy array
    fitness_array = np.asarray(fitness_list)

    # Calculate selection probabilities based on fitness
    selection_probabilities = fitness_array / sum(fitness_array)
    # print(selection_probabilities)

    # Select indices of individuals for the mating pool based on probabilities
    index = np.random.choice(population.shape[0], size=int(len(population) * mating_rate), replace=False,
                             p=selection_probabilities)

    # Extract selected individuals
    mating_pool = population[index]

    # Remove selected individuals from the population
    population = np.delete(population, index, axis=0)

    return mating_pool


def crossover(parents, lower_threshold=[0.3, 0.1, 0.5, 0.3]):
    mating_pool = deepcopy(parents)
    offsprings = []
    while mating_pool.size > 0:
        # Select 2 parents from pool
        mating_idx = np.random.choice(mating_pool.shape[0], 2, replace=False)
        mating_parents = mating_pool[mating_idx]
        parent_1, parent_2 = mating_parents
        ### Begin Crossover
        chromosome_swap_index = random.randrange(len(parent_1.chromosome))
        parent_1_str = str(parent_1.chromosome[chromosome_swap_index])
        parent_2_str = str(parent_2.chromosome[chromosome_swap_index])
        parent_1_components = parent_1_str.split("-")
        parent_2_components = parent_2_str.split("-")

        constant_attrs_1, bitstring_1 = parent_1_components[:-1], parent_1_components[-1]  # type: list, str
        constant_attrs_2, bitstring_2 = parent_2_components[:-1], parent_2_components[-1]  # type: list, str
        # Keep constant attribute
        offspring_1 = "-".join(constant_attrs_1) + "-"
        offspring_2 = "-".join(constant_attrs_2) + "-"

        # day of week: 3 bits, session_start: 4 bits, room_type: 3 bits, active_week: 18 bits
        range_index = [(0, 3), (3, 7), (7, 10), (10, len(bitstring_1))]
        lower_threshold
        for (s, e), thresh in zip(range_index, lower_threshold):
            if random.random() > thresh:
                offspring_1 += bitstring_2[s:e]
                offspring_2 += bitstring_1[s:e]
            else:
                offspring_1 += bitstring_1[s:e]
                offspring_2 += bitstring_2[s:e]

        ### End Crossover
        parent_1.chromosome[chromosome_swap_index] = np.str_(offspring_1)
        parent_2.chromosome[chromosome_swap_index] = np.str_(offspring_2)
        # Save new offsprings and delete crossovered parents
        offsprings.append(parent_1)
        offsprings.append(parent_2)
        mating_pool = np.delete(mating_pool, list(mating_idx), axis=0)

    return np.array(offsprings)


def mutation(population, mutation_rate, lower_threshold=[0.5, 0.1, 0.7, 0.5]):
    _population = deepcopy(population)
    offsprings = []
    # Mutation changes a number of genes as defined by the num_mutations argument. The changes are random.
    for chromosome in _population:
        new_chromosome = []
        for _, gen in enumerate(chromosome.chromosome):
            if random.uniform(0, 1) < mutation_rate:
                # Mutation for each part of bitstring: day, room_type_id,...
                start_bitstring_index = gen.rfind("-") + 1
                range_index = [(0, 3), (3, 7), (7, 10), (10, len(gen.split('-')[-1]))]
                lower_threshold
                for (s, e), thresh in zip(range_index, lower_threshold):
                    if random.random() > thresh:
                        mut_idx = start_bitstring_index + random.randrange(s, e)
                        gen = gen[:mut_idx] + str(random.randint(0, 1)) + gen[mut_idx + 1:]
            new_chromosome.append(gen)
        chromosome.chromosome = new_chromosome
        offsprings.append(chromosome)
    return np.asarray(offsprings)


#############################
# Tracking Chromosome Fitness

def selection(chromosomes, fitness_results: List[int], population_size):
    # Combine chromosomes with their corresponding tracking results
    combined_data = list(zip(chromosomes, fitness_results))

    # Sort the combined data based on tracking results
    sorted_data = sorted(combined_data, key=lambda x: x[1], reverse=False)

    # Select the top population_size chromosomes
    selected_chromosomes = [data[0] for data in sorted_data[:population_size]]
    fitness_list = [data[1] for data in sorted_data[:population_size]]

    return np.asarray(selected_chromosomes), np.asarray(fitness_list)


"""## GA Constraints

### Constraints Type

**Lưu ý**, xem thật kỹ `class ConstraintBase`, các ràng buộc đều phải kế thừa class này cũng như tên class mới phải `endswith("Constraint")`
"""


class ConstraintTypeBase:
    pass


class ConstraintTypeSoft(ConstraintTypeBase):
    penalty = 5


class ConstraintTypeHard(ConstraintTypeBase):
    penalty = 10


# Với các lỗi về invalid constraint, GA sẽ optimize để dần giảm thiếu hóa các lỗi này trước, sau khi các lỗi này giảm, các lỗi khác Invalid sẽ bắt đầu được xét

class ConstraintBase:
    InvalidIndices = []

    def __init__(self, _name: str, _type: ConstraintTypeBase):
        self.type = _type
        self.name = _name  # Tên của ràng buộc
        self.active = True  # Nếu không xét đến Constraint thì đổi về False

        self.penalty = {
            ConstraintTypeSoft: ConstraintTypeSoft.penalty,
            ConstraintTypeHard: ConstraintTypeHard.penalty
        }.get(type(_type), 0)

        self.vars_depend = ""  # "day", "session_start", "room_type_id", "weeks_bitstring"

    def __call__(self, chromosome):
        pass

    @property
    def fitness(self):
        return 0


"""### Invalid Constraints"""


class InvalidDayConstraint(ConstraintBase):
    def __init__(self):
        super().__init__("Invalid Day", ConstraintTypeHard())
        self._logging = defaultdict(int)
        self.vars_depend = "day"
        self.penalty = 50

    def __call__(self, chromosome):
        for idx, gen in enumerate(chromosome.chromosome):
            info = parse_gen(gen)
            if info.day not in VALID_DAY:
                self._logging['invalid_day_cases'] += 1
                ConstraintBase.InvalidIndices.append(idx)
        return self._logging

    @property
    def fitness(self):
        return sum(self._logging.values()) * self.penalty


class InvalidSessionConstraint(ConstraintBase):
    def __init__(self):
        super().__init__("Invalid Session", ConstraintTypeHard())
        self.active = True
        self._logging = defaultdict(int)
        self.vars_depend = "session_start"
        self.penalty = 100

    def __call__(self, chromosome):
        for idx, gen in enumerate(chromosome.chromosome):
            info = parse_gen(gen)

            duration = NUMBER_OF_SESSION[info.subject_id]

            self._logging['total_invalid_session_cases'] += 1  # if no case error, minus 1 later
            ConstraintBase.InvalidIndices.append(idx)
            if info.session_start not in VALID_SESSION_START:
                self._logging['invalid_start_session'] += 1
            elif info.session_start + duration not in VALID_SESSION:
                self._logging['invalid_end_session'] += 1
            else:  # no case error, minus 1
                self._logging['total_invalid_session_cases'] -= 1
                ConstraintBase.InvalidIndices = ConstraintBase.InvalidIndices[:-1]

        return self._logging

    @property
    def fitness(self):
        return sum(self._logging.values()) * self.penalty


class InvalidRoomTypeIdConstraint(ConstraintBase):
    def __init__(self):
        super().__init__("Invalid Room Type Id", ConstraintTypeSoft())
        self.active = True
        self._logging = defaultdict(int)
        self.invalid_room_type_id_cases = 0
        self.vars_depend = "room_type_id"

    def __call__(self, chromosome):
        for idx, gen in enumerate(chromosome.chromosome):
            info = parse_gen(gen)

            if info.room_type_id not in VALID_ROOM_TYPE_ID:
                self._logging['invalid_room_type_id_cases'] += 1
                ConstraintBase.InvalidIndices.append(idx)

        return self._logging

    @property
    def fitness(self):
        return sum(self._logging.values()) * self.penalty


"""### Room Constraints"""


class SmallerRoomConstraint(ConstraintBase):
    def __init__(self):
        super().__init__("Smaller Room", ConstraintTypeSoft())
        self.active = True
        self._logging = defaultdict(int)
        self.vars_depend = "room_type_id"

    def __call__(self, chromosome):
        for idx, gen in enumerate(chromosome.chromosome):
            if idx in ConstraintBase.InvalidIndices:
                continue
            info = parse_gen(gen)
            if int(info.room_type_id) < int(get_min_cap_room_type_id(info.subject_id, info.group_id)):
                self._logging['smaller_room'] += 1

        return self._logging

    @property
    def fitness(self):
        return sum(self._logging.values()) * self.penalty


class OverloadRoomConstraint(ConstraintBase):
    def __init__(self):
        super().__init__("Overload Room", ConstraintTypeSoft())
        self.active = False
        self._logging = defaultdict(int)
        self.vars_depend = "room_type_id"

    def __call__(self, chromosome):
        time_loc_dict = defaultdict(int)

        for idx, gen in enumerate(chromosome.chromosome):
            if idx in ConstraintBase.InvalidIndices:
                continue
            info = parse_gen(gen)

            duration = NUMBER_OF_SESSION[info.subject_id]
            facility = FACILITY[info.group_id[
                                :-2]]  # get value of key (L or CC or CN) because the 2 last letter is number of group like 01, 02
            for idx, bit in enumerate(info.weeks_bitstring):
                if bit == '1':
                    for session in range(info.session_start, info.session_start + duration):
                        key = f"{idx + 1}-{info.day}-{session}-{facility}-{info.room_type_id}"
                        time_loc_dict[key] += 1

        for key, _count in time_loc_dict.items():
            facility, room_type_id = key.split('-')[-2:]
            try:
                if _count > NUMBER_OF_ROOM[f"{facility}-{room_type_id}"]:
                    self._logging['overload_room_cases'] += 1
            except:
                self._logging['invalid_cases'] += 1

        return self._logging

    @property
    def fitness(self):
        return sum(self._logging.values()) * self.penalty


"""### Teacher Constraints"""


class TakeABreakConstraint(ConstraintBase):
    def __init__(self):
        super().__init__("Take A Break", ConstraintTypeSoft())
        self.active = True
        self.vars_depend = "session_start"
        self._logging = defaultdict(int)
        self.penalty = 10

    def __call__(self, chromosome):
        time_loc_dict = defaultdict(int)

        for idx, gen in enumerate(chromosome.chromosome):
            if idx in ConstraintBase.InvalidIndices:
                continue
            info = parse_gen(gen)

            if info.session_start == 7:
                self._logging['not_break_at_lunch_cases'] += 1

        return self._logging

    @property
    def fitness(self):
        return sum(self._logging.values()) * self.penalty


class NumberTeacherRequireConstraint(ConstraintBase):
    """

    """

    def __init__(self):
        super().__init__("Number Teacher Require", ConstraintTypeHard())
        self.active = False

    def __call__(self, chromosome):
        for idx, gen in enumerate(chromosome.chromosome):
            if idx in ConstraintBase.InvalidIndices:
                continue
            info = parse_gen(gen)
            attributes = ClassDictGlobal[f"{info.subject_id}-{info.group_id}"]

    @property
    def fitness(self):
        return self.overlap_cases * self.penalty


class TeacherStayAtFacilityConstraint(ConstraintBase):
    """
    Mỗi ngày, giảng viên chỉ giảng dạy tại 1 cơ sở
    """

    def __init__(self):
        super().__init__("Teacher Stay At Facility", ConstraintTypeSoft())
        self.active = True
        self._logging = defaultdict(int)

    def __call__(self, chromosome):
        # dict[Week-Day] = { Facility1 : [Teacher1, Teacher2, Teacher3], Facility2 : [Teacher1, Teacher4, Teacher5]}
        _dict = defaultdict(lambda: defaultdict(list))
        for idx, gen in enumerate(chromosome.chromosome):
            if idx in ConstraintBase.InvalidIndices:
                continue
            info = parse_gen(gen)
            attributes = ClassDictGlobal[f"{info.subject_id}-{info.group_id}"]
            for idx, bit in enumerate(info.weeks_bitstring):
                if bit == '1':
                    _dict[f"{idx + 1}-{info.day}"][attributes.facility] += [attributes.teacher_id]
        for _, facilities in _dict.items():
            if len(facilities) == 1:  # just 1 facility is working at this day
                continue
            # list teacher_ids in each facility
            teacher_ids = facilities.values()
            # Map to set
            sets = [set(lst) for lst in teacher_ids]
            # Find intersection
            teacher_id_intersection = set.intersection(*sets)
            self._logging['num_teacher_two_facilities'] += len(teacher_id_intersection)
        return self._logging

    @property
    def fitness(self):
        return sum(self._logging.values()) * self.penalty


"""### Week Learning Constraints"""


class SubjectSameMainTermConstraint(ConstraintBase):
    """
    Các môn học của cùng 1 học kỳ chính (theo sơ đồ đào tạo) không nên diễn ra trùng nhau, để sinh viên có nhiều lựa chọn TKB phù hợp
    Các lớp học có cùng mã môn có thể diễn ra cùng thời điểm (phụ thuộc vào số lượng giảng viên của môn). Tham khảo class NumberTeacherRequireConstraint
    """

    def __init__(self):
        super().__init__("Subject Same Main Term", ConstraintTypeSoft())
        self.active = True
        self._logging = defaultdict(int)
        self.vars_depend = "session_start"
        self.penalty = 10

    def __call__(self, chromosome):
        # For all class (=tuple(subject_id, group_id)), group them by facility, faculty, main_term
        # e.g dict["DAn-CS-3"] = [object(CO2003,L01), object(CO2003, L02), object(CO2007, L01)]
        subject_same_term_in_week = defaultdict(list)
        for idx, gen in enumerate(chromosome.chromosome):
            if idx in ConstraintBase.InvalidIndices:
                continue
            info = parse_gen(gen)
            attributes = ClassDictGlobal[f"{info.subject_id}-{info.group_id}"]
            _key = f"{attributes.facility}-{attributes.faculty}-{attributes.main_term}"
            subject_same_term_in_week[_key].append(info)

        # e.g dict["Monday-2"] = [CO2003, CO2007]
        time_points = defaultdict(list)
        for classes in subject_same_term_in_week.values():
            for _class in classes:  # type(_class) is GenStruct
                day = _class.day
                # parse learning sessions to unit session
                duration = NUMBER_OF_SESSION[_class.subject_id]
                for session in range(_class.session_start, _class.session_start + duration):
                    time_points[f"{day}-{session}"].append(f"{_class.subject_id}-{_class.group_id}")

        # List all combinations between 2 different subject_ids at the same timepoint
        overlap_classes = []
        for classes in time_points.values():
            _combinations = list(combinations(classes, 2))
            _combinations = [x for x in _combinations if x[0].split('-')[0] != x[1].split('-')[0]]  # CO2003 != CO2007
            overlap_classes += _combinations

        self._logging['overlap_classes_mainterm'] = len(overlap_classes) // 18

        return self._logging

    @property
    def fitness(self):
        return sum(self._logging.values()) * self.penalty


# Các môn cùng mã môn nên có thời khóa biểu tuần học giống nhau
class SameLearningWeekConstraint(ConstraintBase):
    def __init__(self):
        super().__init__("Same Learning Week", ConstraintTypeHard())
        self._logging = defaultdict(int)
        self.vars_depend = "week"
        self.penalty = 50

    def __call__(self, chromosome):
        subjects = defaultdict(list)
        for idx, gen in enumerate(chromosome.chromosome):
            info = parse_gen(gen)
            subjects[info.subject_id].append(info.weeks_bitstring)
        for subject_id, calendars in subjects.items():
            _combinations = list(combinations(calendars, 2))
            self._logging["same_subject_not_same_week"] += sum(1 if x[0] != x[1] else 0 for x in _combinations)
        return self._logging

    @property
    def fitness(self):
        return sum(self._logging.values()) * self.penalty


class MidTermOccurConstraint(ConstraintBase):
    def __init__(self):
        super().__init__("Kiểm tra tuần thi giữa kỳ các môn", ConstraintTypeHard())
        self._logging = defaultdict(int)
        self.active = False
        self.vars_depend = "week"
        self.penalty = 50

    def __call__(self, chromosome):
        for idx, gen in enumerate(chromosome.chromosome):
            info = parse_gen(gen)
            # TODO
        return self._logging

    @property
    def fitness(self):
        return sum(self._logging.values()) * self.penalty


"""### Constraints Manager"""


def get_all_constraints() -> list:
    # List all class names
    constraints = [(name, obj()) for name, obj in globals().items() if
                   name.endswith("Constraint") and isinstance(obj, type) and issubclass(obj,
                                                                                        ConstraintBase) and obj().active]
    return constraints


# class TrackingLog:
#     def __init__(self):
#         self.total_invalid_cases = 0
#         self.invalid_day = 0
#         self.invalid_session_start = 0
#         self.invalid_session_end = 0
#         self.invalid_room_type_id = 0
#         self.smaller_room = 0
#         self.overload_room_cases = 0

# def calculate_fitness(tracking_log: TrackingLog):
#     track = vars(tracking_log)
#     global SC_penalty_point, HC_penalty_point
#     hard_cases = track['invalid_day'] + track['invalid_session_start'] + track['invalid_session_end'] + track['invalid_room_type_id'] + track['overload_room_cases']
#     soft_cases = track['smaller_room']
#     return hard_cases * HC_penalty_point + soft_cases * SC_penalty_point

def tracking_chromosome_fitness(chromosome):
    fitness = 0
    error_cases = {}
    vars_depend_fitness = defaultdict(int)
    active_constraints = []
    ConstraintBase.InvalidIndices = []
    for constraint_name, constraint_func in get_all_constraints():
        # print(constraint_name)
        active_constraints.append(constraint_name)
        for key, value in constraint_func(chromosome).items():
            if key in error_cases:
                error_cases[key] += value
            else:
                error_cases[key] = value
        # print(constraint_func.fitness)
        fitness += constraint_func.fitness
        vars_depend_fitness[constraint_func.vars_depend] += constraint_func.fitness

    return {
        "fitness": fitness,
        "error_cases": error_cases,
        "vars_depend_fitness": vars_depend_fitness,
        "active_constraints": active_constraints,
    }


tracking_chromosome_fitness(chromosome)

# Kiểm tra xem các lớp đã fixed trước đó có bị overlap hay invalid không
tracking_chromosome_fitness(fixed_chromosome)

"""# Train GA"""

num_generations = 1
population_size = 20

mating_rate = 0.6
crossover_rate = 0.8
mutation_rate = 0.3


# Hàm này dùng để tăng khả năng mutation cũng như crossover đặc biệt cho các đoạn gen cần thiết để giảm fitness cho toàn bộ invidual,
# tuy nhiên, kết quả thực nghiệm cho thấy, tập trung thay đổi vào 1 trường dữ liệu ko tạo ra biến thể tốt,
# vì các trường ko phải hoàn toàn độc lập
def generate_lower_threshold(vars_depend_fitness: list):
    vars_depend_fitness = np.array(vars_depend_fitness).astype(float)
    vars_depend_fitness /= np.sum(vars_depend_fitness)
    vars_depend_fitness = [min(max(x, 0.1), 0.9) for x in vars_depend_fitness]
    vars_depend_fitness = [1 - x for x in vars_depend_fitness]
    return vars_depend_fitness


# generate_lower_threshold([0, 0, 50, 0])

# Sau khi GA, kết hợp population với từng fixed_chromosome để đánh giá kết quả toàn cục
def merge_with_fixed_chromosome(chromosome):
    global fixed_chromosome
    merged_chromosome = deepcopy(chromosome)
    merged_chromosome.chromosome = np.concatenate((fixed_chromosome.chromosome, merged_chromosome.chromosome))
    return merged_chromosome


# Để tăng tốc quá trình GA, bên dưới đây đi theo hướng: khởi tạo population nhiều lần, và GA 1 epoch
# Để sửa lại theo đúng lý thuyết GA, bỏ vòng lặp while

population = init_population(df0, df3, population_size)
fitness_list = None
global_logging = []
exists = False
while not exists:
    if exists:
        break
    fitness_list = None
    global_logging = []
    population = init_population(df0, df3, population_size)
    for gen_idx in tqdm(range(num_generations)):
        ### Select the best parents for mating
        parents = select_mating_pool(population, mating_rate, fitness_list)
        ### Crossover
        offspring_crossover = crossover(parents,
                                        # crossover_lower_threshold
                                        )
        ### Mutation: Take every individual in the offspring after crossover to mutate with a given rate
        offspring_mutation = mutation(offspring_crossover,
                                      mutation_rate,
                                      #   mutation_lower_threshold
                                      )
        total_chromosome = np.concatenate(
            (
                deepcopy(offspring_crossover),
                deepcopy(offspring_mutation),
                deepcopy(population),
            )
        )  # combine current population and offspring chromosomes
        fitness_results = []
        for chromosome in total_chromosome:
            tracking_result = tracking_chromosome_fitness(merge_with_fixed_chromosome(chromosome))
            fitness_results.append(tracking_result['fitness'])

        ### Selecting a new population for the next generation from parents and offsprings
        best_population_list, fitness_list = selection(total_chromosome, fitness_results, population_size)
        population = best_population_list

        ### Show the best
        tracking_result = tracking_chromosome_fitness(merge_with_fixed_chromosome(population[0]))
        # tracking_log = vars(track_result['tracking_log'])
        fitness = tracking_result['fitness']
        # global_logging.append({
        #     key: val for key, val in list(tracking_log.items()) + [("index", gen_idx), ("fitness", fitness)]
        # })
        vars_depend_fitness = tracking_result['vars_depend_fitness']
        # mutation_lower_threshold = generate_lower_threshold([vars_depend_fitness['day'], vars_depend_fitness['session_start'], vars_depend_fitness['room_type_id'], vars_depend_fitness['weeks_bitstring']])
        # crossover_lower_threshold = 1
        # print(mutation_lower_threshold)
        print('||' * 20)
        print('error_cases', tracking_result['error_cases'])
        global_logging.append(tracking_result['error_cases'])
        global_logging[-1]['fitness'] = fitness
        if fitness == 0 or tracking_result['error_cases']['total_invalid_session_cases'] <= 6:
            exists = True
            break
        print(fitness)

tracking_chromosome_fitness(merge_with_fixed_chromosome(population[0]))



"""# Result Tracking

## Plot GA Fitness and Constraints
"""

# import matplotlib.pyplot as plt

# # Extract features from global_logging
# features = list(tracking_result['error_cases'].keys())

# # Iterate over each feature
# for feature in features:
#     # Create a new figure for each feature
#     plt.figure()

#     # Extract data for the current feature
#     data = [entry[feature] for entry in global_logging]

#     # Plot the line chart with dots at each index
#     plt.plot(range(len(data)), data)

#     # Add labels and title
#     plt.xlabel('Epoch')
#     plt.ylabel(feature)
#     plt.title(f'Line Chart for {feature}')
#     # Save the figure
#     plt.savefig(f'{feature}.png', format='png')
# # Show all the plots
# plt.show()

"""## Save as "Phản hồi"
"""

import pandas as pd

# Assuming data is a list of dictionaries where each dictionary represents a row of data
# Example:
data = []
for gen in merge_with_fixed_chromosome(population[0]).chromosome:
    info = parse_gen(gen)
    new_row = {
        'Mã môn học': info.subject_id,
        'Tên môn học': SUBJECT_ID_TO_NAME.get(info.subject_id, "INVALID"),
        'Loại hình lớp': PROGRAM_ID_REVERSE.get(GROUP_ID_TO_PROGRAM_ID.get(info.group_id[:-2], "INVALID"), "INVALID"),
        'Mã nhóm': info.group_id,
        'Số tiết': NUMBER_OF_SESSION.get(info.subject_id, "INVALID"),
        'Mã GV': ClassDictGlobal[f"{info.subject_id}-{info.group_id}"].teacher_id,
        'Mã Phòng': None,
        'Loại Phòng': ROOM_TYPE_ID_REVERSE.get(info.room_type_id, "INVALID"),
        'Thứ': info.day,
        'Tiết BD': info.session_start,
    }
    for idx, bit in enumerate(info.weeks_bitstring):
        new_row[f"Week {idx + 1}"] = 'x' if bit == '1' else None
    data.append(new_row)

# Create a DataFrame from the data
df = pd.DataFrame(data)
k = len(fixed_chromosome.chromosome)
df = df.style.apply(lambda x: ['background: lightblue' if i < k else '' for i in range(len(x))])
# Define the file path to save the Excel file
file_path = '/Users/vinhvu/Sched/BK-Calendar-Ver1-12.xlsx'

# Write the DataFrame to an Excel file
df.to_excel(file_path, index=False)

print("Excel file saved successfully.")

# !cp /content/{file_path} /gdrive/MyDrive/HCMUT-Scheduling/

"""## Save as "Tham khảo HK231"
"""

import pandas as pd

# Assuming data is a list of dictionaries where each dictionary represents a row of data
# Example:
data = []
for gen in population[0].chromosome:
    info = parse_gen(gen)
    new_row = {
        'f_malp': "",
        'f_mamh': info.subject_id,
        'f_tenmhvn': SUBJECT_ID_TO_NAME.get(info.subject_id, "INVALID"),
        'f_dvht': SUBJECT_INFO[info.subject_id]['f_dvht'],
        'f_ts': SUBJECT_INFO[info.subject_id]['f_ts'],
        'f_lt': SUBJECT_INFO[info.subject_id]['f_lt'],
        'f_bt': SUBJECT_INFO[info.subject_id]['f_bt'],
        'f_tn': SUBJECT_INFO[info.subject_id]['f_tn'],
        'f_btl': SUBJECT_INFO[info.subject_id]['f_btl'],
        'f_da': SUBJECT_INFO[info.subject_id]['f_da'],
        'f_la': SUBJECT_INFO[info.subject_id]['f_la'],
        'f_mh_mabm': None,
        'f_mh_tenbm': PROGRAM_ID_REVERSE.get(GROUP_ID_TO_PROGRAM_ID.get(info.group_id[:-2], "INVALID"), "INVALID"),
        'f_manh': info.group_id,
        'f_sosv': None,
        'f_sstb': 0,
        'f_succhua': ROOM_TYPE_ID_REVERSE.get(info.room_type_id, "INVALID"),
        'f_sosv1': None,
        'f_sodk': None,
        'f_tuan1': 0,
        'f_thu': {i: calendar.day_name[i] for i in range(7)}.get(info.day - 2, "INVALID"),
        'f_tietbd': info.session_start if NUMBER_OF_SESSION.get(info.subject_id,
                                                                "INVALID") != "INVALID" and NUMBER_OF_SESSION.get(
            info.subject_id, "INVALID") + info.session_start in VALID_SESSION else "INVALID",
        'f_sotiet': NUMBER_OF_SESSION.get(info.subject_id, "INVALID"),
        'f_manv': None,
        'f_holotvn': None,
        'f_tenvn': None,
        'f_mabm': None,
        'f_tenbm': None,
        'f_tenph': None,
        'f_diadiem': FACILITY_ID[FACILITY[info.group_id[:-2]]],
        'f_mamh_lt': None,
        'f_makhoa': 'MT',
        'f_tenkhoa': 'KH & KT Máy tính',
        'f_manh_lt': None
    }
    for idx, bit in enumerate(info.weeks_bitstring):
        new_row[f"t{idx + 1}"] = 'x' if bit == '1' else None
    data.append(new_row)

# Create a DataFrame from the data
df = pd.DataFrame(data)

# Define the file path to save the Excel file
file_path = '/Users/vinhvu/Sched/TKB-241.xlsx'

# Write the DataFrame to an Excel file
df.to_excel(file_path, index=False)

print("Excel file saved successfully.")

"""# Appendix: Hyper parameters Number of room in each facility

```
# Param 1
NUMBER_OF_ROOM = { # '-'.join(facility, room_type_id) BK-DAn, BK-LTK
    "DAn-1": 30, # loại phòng 40 chỗ
    "DAn-2": 5, # loại phòng 60 chỗ
    "DAn-3": 20, # loại phòng 80 chỗ
    "DAn-4": 5, # loại phòng 140 chỗ
    "DAn-5": 3, # loại phòng 160 chỗ
    "DAn-6": 2, # loại phòng 200 chỗ (hội trường, 211H1)

    "LTK-1": 30,
    "LTK-2": 5,
    "LTK-3": 20,
    "LTK-4": 5,
    "LTK-5": 3,
    "LTK-6": 2
}
# Param 2
NUMBER_OF_ROOM = { # '-'.join(facility, room_type_id) BK-DAn, BK-LTK
    "DAn-1": 30, # loại phòng 40 chỗ
    "DAn-2": 5, # loại phòng 60 chỗ
    "DAn-3": 10, # loại phòng 80 chỗ
    "DAn-4": 5, # loại phòng 140 chỗ
    "DAn-5": 3, # loại phòng 160 chỗ
    "DAn-6": 2, # loại phòng 200 chỗ (hội trường, 211H1)

    "LTK-1": 30,
    "LTK-2": 5,
    "LTK-3": 10,
    "LTK-4": 5,
    "LTK-5": 3,
    "LTK-6": 2
}
```



```
tracking_log dict_items([('total_invalid_cases', 0), ('invalid_day', 0), ('invalid_session_start', 0), ('invalid_room_type_id', 0), ('smaller_room', 0), ('overload_room_cases', 0)])

```

```
NUMBER_OF_ROOM = { # '-'.join(facility, room_type_id) BK-DAn, BK-LTK
    "DAn-1": 25, # loại phòng 40 chỗ
    "DAn-2": 10, # loại phòng 60 chỗ
    "DAn-3": 15, # loại phòng 80 chỗ
    "DAn-4": 5, # loại phòng 140 chỗ
    "DAn-5": 5, # loại phòng 160 chỗ
    "DAn-6": 5, # loại phòng 200 chỗ (hội trường, 211H1)

    "LTK-1": 25,
    "LTK-2": 10,
    "LTK-3": 15,
    "LTK-4": 5,
    "LTK-5": 5,
    "LTK-6": 5
}
```



```
tracking_log dict_items([('total_invalid_cases', 6), ('invalid_day', 1), ('invalid_session_start', 3), ('invalid_room_type_id', 2), ('smaller_room', 1), ('overload_room_cases', 0)])
```

```
NUMBER_OF_ROOM = { # '-'.join(facility, room_type_id) BK-DAn, BK-LTK
    "DAn-1": 25, # loại phòng 40 chỗ
    "DAn-2": 10, # loại phòng 60 chỗ
    "DAn-3": 10, # loại phòng 80 chỗ
    "DAn-4": 5, # loại phòng 140 chỗ
    "DAn-5": 5, # loại phòng 160 chỗ
    "DAn-6": 5, # loại phòng 200 chỗ (hội trường, 211H1)

    "LTK-1": 25,
    "LTK-2": 10,
    "LTK-3": 10,
    "LTK-4": 5,
    "LTK-5": 5,
    "LTK-6": 5
}
```



```
tracking_log dict_items([('total_invalid_cases', 4), ('invalid_day', 1), ('invalid_session_start', 3), ('invalid_room_type_id', 0), ('smaller_room', 1), ('overload_room_cases', 1)])


```

```
NUMBER_OF_ROOM = { # '-'.join(facility, room_type_id) BK-DAn, BK-LTK
    "DAn-1": 20, # loại phòng 40 chỗ
    "DAn-2": 15, # loại phòng 60 chỗ
    "DAn-3": 10, # loại phòng 80 chỗ
    "DAn-4": 5, # loại phòng 140 chỗ
    "DAn-5": 5, # loại phòng 160 chỗ
    "DAn-6": 5, # loại phòng 200 chỗ (hội trường, 211H1)

    "LTK-1": 20,
    "LTK-2": 15,
    "LTK-3": 10,
    "LTK-4": 5,
    "LTK-5": 5,
    "LTK-6": 5
}
```



```
tracking_log dict_items([('total_invalid_cases', 44), ('invalid_day', 10), ('invalid_session_start', 18), ('invalid_room_type_id', 17), ('smaller_room', 4), ('overload_room_cases', 3)])

```

# Appendix: Visualize helper function
"""


def visualize_calendar(chromosome):
    time_loc_dict = {}
    global_active = []
    keys_index = ['week', 'day', 'session_start', 'num_session', 'facility', 'room_type_id']
    for gen in chromosome.chromosome:
        info = parse_gen(gen)

        facility = FACILITY[info.group_id[
                            :-2]]  # get value of key (L or CC or CN) because the 2 last letter is number of group liek 01, 02
        for idx, bit in enumerate(info.weeks_bitstring):
            if bit == '1':
                _key = {
                    "week": idx + 1,
                    "day": info.day,
                    "session_start": info.session_start,
                    "num_session": NUMBER_OF_SESSION[info.subject_id],
                    "facility": facility,
                    "room_type_id": info.room_type_id
                }
                _key = tuple(list(_key.values()))
                if _key in time_loc_dict:
                    time_loc_dict[_key] += [(info.subject_id, info.group_id)]
                else:
                    time_loc_dict[_key] = [(info.subject_id, info.group_id)]

                global_active.append(_key)

    sort_keys = ['week', 'facility', 'day', 'session_start', 'room_type_id']
    sort_keys = [keys_index.index(key) for key in sort_keys]
    sorted_global_active = sorted(global_active, key=lambda x: tuple(x[i] for i in sort_keys))

    def add_key_name(key):
        week, day, session_start, num_session, facility, room_type_id = key
        day = {i: calendar.day_name[i] for i in range(7)}.get(day - 2)
        key = f"Week {week}|Facility BK-{facility}|{day}|Session {session_start}-{session_start + num_session}|Room Type {room_type_id}"
        return key

    result = {add_key_name(key): time_loc_dict[key] for key in sorted_global_active}
    return result


visualize_calendar(population[0])

import json

with open("BK-Calendar.json", 'w') as json_file:
    json.dump(visualize_calendar(population[0]), json_file, indent=4)
